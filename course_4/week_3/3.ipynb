{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BOjujz601HcS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zswl7jRtGzkk"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEGCAYAAACO8lkDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO2dd5hU1fnHv+8uu/TOgvQFBARBQFcQsSPYBUusMcSYmBhLjCYGe4s/SWJiisZeMDF2jUQUKQKKBVikgxRhkQWEpZeFZcv7+2Punblz595pe885szvv53n22Zk7d+a8t533nPe8hZgZgiAIguAkx7QAgiAIQuYhykEQBEGIQZSDIAiCEIMoB0EQBCEGUQ6CIAhCDA1MCxAE7dq148LCQtNiCIIg1CkWLFiwnZkLvD6rF8qhsLAQxcXFpsUQBEGoUxDRBr/PxKwkCIIgxCDKQRAEQYhBlIMgCIIQgygHQRAEIQZRDoIgCEIMxpQDEfUlokWOv71EdCsRtSGiaUS0xvrf2pSMgiAI2Yox5cDMq5h5MDMPBnAcgHIA7wEYD2AGM/cGMMN6LwiCIGgkU8xKIwF8y8wbAIwBMNHaPhHAWGNSCYIgJKC6hvHm/I2oqq4xLUqgZIpyuALAa9brDsy8BQCs/+29vkBE1xNRMREVl5WVaRJTEAQhmtfmfYc73lmCl78oMS1KoBhXDkSUD+BCAG+l8j1mfpaZi5i5qKDAM/pbEARBObvLDwMAtu2rMCxJsBhXDgDOAfA1M2+13m8loo4AYP3fZkwyQRCEBOw8UAkAePbTdYYlCZZMUA5XImJSAoBJAMZZr8cBeF+7RIIg1Dlqahg1NfrLHu89VKm9TR0YVQ5E1ATAKADvOjZPADCKiNZYn00wIZsgCHWL434/DcMenaG93YOHq7W3qQOjWVmZuRxAW9e2HQh5LwmCICTNrnIzI/jJS7cYaVc1mWBWEgRBEDIMUQ6CIAhCDKIcBEEQ6iiV1TWoVrQIL8pBEAShjnL0fR/jsamrlPy2KAdBEAQhBlEOgiAERk0N48U563Gosn66d2YTohwEQQiMD5ZuwUMfrEC/+6aYFkWoJaIcBEEIjIOHqwAArD9QWQgYUQ6CIAQGgUyLgI07y02LoA2GOi0sykEQ6iFb9x7Cpt0H9TdsXjfghlcXmBZBK6pOudH0GYIgqGHY/4VyDJVMOE9ruzlkXjvUs5o7xpCZg1DvWb55D276z9f1rlJXJmJeNQDVNWav88ad5eB6sOgiykGo99zy2kJ8sGQL1m8/YFqUek8GTByweut+Y21/8/1enPzHmXjus7pf20GUg1DvoUzosbKEbD/V3+0ILYbPW79TS3sqJyiiHISswcRE/8In5qBw/GSs3WZuNKuTTPBWyjZUKWRRDkK9x2THvKR0DwBg8cbdRtrXXRmtykAlNtM0yvPqRuu+kjRdCa4VEb1NRN8Q0UoiGk5EbYhoGhGtsf63NimjUH8wuUZoqunFpXqVUjYu+t8+qq/H1rqvJE3PHP4GYAozHwVgEICVAMYDmMHMvQHMsN4LQp2mxpBmuuifX2htrzILZw75DUx3o2owdlRE1ALAKQBeAABmPszMuwGMATDR2m0igLFmJBTqGyqjSYUQTjPWHkNlOwGAmY24k+o2q6lszaTK6wmgDMBLRLSQiJ4noqYAOjDzFgCw/rf3+jIRXU9ExURUXFZWpk9qoc5i1PU8S/TSgM4twq+//m6XMTnGPPk5etz5oZa2nEpokbW2tG1fhZa2AXVOACaVQwMAxwJ4ipmHADiAFExIzPwsMxcxc1FBQYEqGQUhELJn1hLpqKpqGJt2HzQygrcdAXTzwpz1RtsPEpPKoRRAKTPPtd6/jZCy2EpEHQHA+r/NkHxCPcPkzCELTfEoLtmJERM+wZvFG02Log1VJTtNYEw5MPP3ADYSkb3UPxLACgCTAIyzto0D8L4B8eo1X6zdjooqKcaik3qQTSFlVn6/DwBQXGLOvCSkj+ll9psBvEpESwAMBvB/ACYAGEVEawCMst4LAbFyy15c9fxcPPzBCu1tL9u0BwcqqrS3a5M9ph2TRM4xxWwRgkalyc5oVlZmXgSgyOOjkbplyRZ2lR8GAKzRnH+moqoa5/9jDk46sh3+/dNhWtvOBLJRMc1eHXIUqe+zJtOHJxHS9YxV3+8L52HJBuwO4st1O4zJUFVt7jGu7x2kjddxZqNirA+IcjDEWX/9FKf8aab2dm23N92Pqz26Mblgd8fbS7S2t+9QxM/fZArn7fsrjLqV6rrZnG60Qu0R5ZBlUBYbgldt3ae1vQUbIh2yydM99snPcbGmSGmv49R17NkyO9OFKIcso+6nA6s7NMnPjEKLpbsMlAt1YHLWNGPlVuVtOA/PTqXRUFNKjfoaIS0YRLcdOBtHdc0bRZRDJhy/qU7a5KFfN7FYa3uHq0KJB8cO7qytTVUDPlEOWYYUvtGHMyGbqcR7TnSs93guSGs69Aw4xWFWbNlrWoRaI8ohS8mkB6m+4jzHus/30MI2MdumrlBvYvFi6aa6n0oiVerDMYtyyDJk4mCGw5rrHOQ1iL3QpbvUu057ma6kdnfdRJRDlmHbRGXioJfMMCuZa3vPQfXpu02dYaPJfqWGtBAUd7+3FACw/5C5NBbZiO5ynV5U15jTDibTptR7FJkDslo5bNxZjsLxk1E4frJpUbRRYkVl6/b5z3a27tWX3x/wHlHqqFjmpwJ3ayj8Y9Jl1gsdZjyVZLVy0F1fVwiRaQ+xOiLH+a+vNhiToke7pgCA/h1bGpPhwifmGGvbFDoUokqyWjlkwExfO43yzF9yk7ph0uLNKBw/OavMHC2seAsd6x5+TegunynUHvM9hUGyZwQbIT/X/CU3edb/PmMNAGDTbrNRwzrJyQnZpKuz8H7XQX3tR8z3FAapp9c0LpmQ0sGk506utXinOwHgmMGdsKe8Eocq9RdZyrGOWceiuGRgjVC2X886k0RIKyAT3At1c9nxXY206zzVc9ZuNyIDEBlF6zaxVNcwBj00FZc/+5Xydt1tm1KI2c61L803LUKtyHLlYFoC/ehKCBaPCgOjZxtLN0C3V2eeZc5bvFG/E4TteLHRcAI+1WTCWK9ZQ/Mz86Aw2lMQUQkRLSWiRURUbG1rQ0TTiGiN9b+1qvYzxVZ4zQtzMf4dPbUGnC7Ru62qcLr56/Q1RtoFgFxD9vfpGrKD+lFhBT5qKQ3rOK1eKTzqM43zck2LECjmh5HA6cw8mJntcqHjAcxg5t4AZljvlZAhugGfrdmO1+dv1N6uKTPDN9+bi7EI2981X/x9WRh0qPsc+6136FrnySG9x6x6cJsJysHNGAATrdcTAYxV1VC2u9dlY4bWiFkpu6+9Kpxn1d1R7j1kxu//xc/Xa2knh8jIOmZ9rSHNAKYS0QIiut7a1oGZtwCA9b+91xeJ6HoiKiai4rKysrQarzSZbCbLyBQvltzwgrT6tozm3MmA8+0+x9s0R4nb6Jq1EWWONSIITCuHEcx8LIBzANxIRKck+0VmfpaZi5i5qKCgIK3G7SR02YTz5s2+eUOE1ZI+RDnuUbRq846zubzcyN1dUannOc/JMTNzUIVR5cDMm63/2wC8B2AogK1E1BEArP/bVLXfpmm+qp9OmvklO02LkFV8WxZKH33Pf5cZlqR+4nbf1U0Da2ZowmS6u7wSldWiHGoNETUloub2awCjASwDMAnAOGu3cQDeVyVDUaEyR6ikufHVr421XX9u4+TJ5tmSbkws69g6Qed1NjVZUN2uyZlDBwBziGgxgHkAJjPzFAATAIwiojUARlnvlZAJa5Lb9pmxwwJmgwAPVFThreKN2t2JdZoS/Q4tU1yoVeBc61ipuVQmIzJjsNeWsgFSpAqNRWww8zoAgzy27wAwUpMMUa+zzXvHZB/14P+W483iUnRr0wTDerbV1u6+DEi4t3zzXgzorDZDaibqHx0y5XjMHLLssQ4M0wvSRnHeq5n4MKmmhhk3v7YQCzaoX/dwn983i0sBAAcOq++sh/XIrGCs+nyvmTw2Zg7HsTgHevX5fKsku5WDswC8OTGMsfPAYfxv8WZc8tSXxmTQ4WbYrU0T5W0IidHhXhtRDpFtJs2nyzfvMdZ2bclq5eBUCfXJBS1ZPl2dXnxIkPxOU9oQITuospJmOQcdqr2m4im9ZZvUKQfVPVZWK4eomUP26YZwyVCTHNLkg24Cv06jPtvA4z1Gqp8xhvf9pGvg169ji5ht7y3chDlr1GYhrq8R0kaJF+qfDUgKifqL35XNxrTdugIeO7RoGLPtq3U78cMX5mppP2iyWjl0bNnItAhG6dexuba2sq9LykxUp4yJ56Zr6h6YX7JLSzu59WxKmNXKoXmjvPDrbJk5OB/eehTMGZdMO8z3F20y1vbBw+ZqaSiHgaM7xZp2dFHfXOGzWjk4yRLdEEVFVT3uKDIAv3vquc/0ZAn1QofrsEn8gt9UmlDt66y7PHs2puw2QrbMHJxUZ8vUwYGdT6ueDfKSRseisB+qnzFnhLQbHcWdTEVlSw1pRVw1rBsAYPt+M1XRTFKZhYuTHVqE1pmYgSnLvjcsjUJ8Lq1Jk5aO8VeuT0+pYyE+p56NOLJeOUxesgUAMPGLErOCGODdr0u1tZUp+YSc5oU/T11lUBIzPDZ1tdoG4lxmHbXD/TpoHYW96ls+p6xXDvb1zEYXv9J6XnDeJiqNtONNPRvoJc2O/WaSPV71vFqXTmf6DDdVGgp7ycyhnmFf0J3lh1H0++lYWlp3w92TIUMG8NqxR3U6BwGmz7VXUBYArNm2X7Mk+shx9GitmkS8EVXOHOxf1j1zkAhpxdgLWF+s3Y7t+yvw5My1xmTJFNNLfcT2QXcqB1WpjjMFP+8ZlbeZ6fKkfqP3oY9Mx4rNalOIm4pzkAhpRYRT/Nqdh8EOeu9Bc26GunPv68YeUUYph3qsGxiMBjnZ9Xgz/JVDDQNPz/5Wafv17XTXs8NJHbusoD1qL9NUfKdzq8Yx2/ZVVGpp24tX524w1rYOvGYOW/ceMiWOFhrl6X+8TU9+cxymHbcsqgcD8dYcZq5SVu1YGcaVAxHlEtFCIvrAet+DiOYS0RoieoOIlBZ6zrV83+w+Y9HG3SqbC+N1H5mcOag2xZvsMxgc7jScM8NcxUO9TDCxNGxg5hEf0q2V9jaZI5YAL1QvGMdbc7j2pflaqxAGgXHlAOBXAFY63v8BwOPM3BvALgDXqWzcHlGqzjnjxmuEZTIQr76vd9gPbrYlG9S+SGqdXr/FcNXkRhX5ib7WqnSD3YxT+Uz8ydCY/YJ+vutzDWkQURcA5wF43npPAM4A8La1y0QAY1XKYI8oM0Gr6+if/ZrQqRucXiS6yPVYU9q+vwJff6cnKZsp7A6rXbNIxlAdMxpzi7P+7aqeOUxfuTX8ukfbpkrbcqIqp5PpmcNfAdwBwO6Z2wLYzcy2faUUQGevLxLR9URUTETFZWXpF62xb+KmDY2V0w6j0wzhvp/q+cQhYlZyzRxemGMmz9HucrUR+fb1tK9z1ARCR6SygYAwBkcdZ4920R20apHqW9yQMeVAROcD2MbMC5ybPXb1vJWZ+VlmLmLmooKCgrTlsG9iezTrtVCsi1mr9FVmc4/sdJq03E2tK1Pvd++1IA2oy0vjpEvrxshz5XX4wdPqS7MSeZfN3LpP3UK86TGGUyk1zMvFk1cdG35v2qJY1wZgJmcOIwBcSEQlAF5HyJz0VwCtiMgexncBsFmlEPbNVGUlodu025z2/8s0xakNHOTkuJWD2vaiq+5FN3bGn2crbtw/CE5lmmWnLdp9fnUFooVdtR1q8NdvLFbe7kfLtnhu/2xNGZ5R6FLqNh05b/O3F+hLF+OFaQeFVDGmHJj5TmbuwsyFAK4A8AkzXw1gJoBLrd3GAXhfpRzXndQDAHBs99bhbXvK1buUml4AbuBSDjpvXBNHbjsmuWdIOmYO1TVsLD3LLute1rUEYN/XFT5reNe8MA+PfvSNorajj5Ogp8ZCss9O0LeA6mfW9JqDF78DcBsRrUVoDeIFlY0N69kWANC2acRjVuW0O1Nwm5Xq2pQ3HXJzKKaTnrRY6cQUgNnZqCmcI/je7Ztpa9e91uFeZzhQoc5d3Nm2l04yPSBMlYxQDsw8i5nPt16vY+ahzHwkM/+AmZVGpdmdZLbUcwgXJnHZwFU+NLFC6GvKSQ6ZtzvrwvRhOu+ue8/vr6VN5thBj3vmcP+k5YG1d6CiCrsORBwLEnlo1bV7LyOUg0lMZWU1fZ/kEkXNlqau2Bpn72AxdeyZljXT2bGowLnOoOvI7WvrPNU6zzsRhQPwiGKPO8h1h1P/NBNDHp7maDvBF0w/9CkiyiEnu2YONjk5ZCyP1H6dsxQHmZZv/xf/XpB4pzqKM6+Tbp3czOGW7tX2X6cH4/jhLhCW6P6SBek6Ro6Pi6Mplm/WkzI8l0hvmVCDpzecUjnDZg4m/eJV2b/tn7155JFKfj8ZGjbIDb/2eqz/On0NFgeYJidsqg3YrLRlz0G8E2emU68jpDOBiP+73nb9LuyyTZqUg8GZgwkIFOO+m024be9vFat162zVWGlKNF+IEI4pIZBvWpwxT34eeNuJ7q91ZfuxZU/yA4Krn5uL299anHA9UFJ2K4J8XBxNoUtJ5eToKZ2YSWSaWUkliWYGd7yzRFXLANRHIydLl9b6glrd99eDFx4d9f7Sp7/E8Ec/Sfr37KzBpvqmrFcO3kVgzKH6RrDtng1ycrIuCZ3uDivRpVTt2mjSiqYjvsCNfT6dTR/TRV92WPcIf9yJhUrb27izXOnvJ1QORNSBiF4goo+s9/2JSGmmVJ2E1xw0a2e/xSldvtA5lH0zh0zzVvILFNOFynvNHYymC0LES0v35XZezyDaTqRgRz3+ae0biUMyM4eXAXwMoJP1fjWAW1UJpJtw5Kyjo3R7Iejk3veD88OOx07FbpRuTHpq2J1gppmVdmi+Bu7aDl9/F3ztEq/01boI32Gam37pczXJG22vPueTU1PDeGDScuzYr74oWTLKoR0zvwkrc6qVMbVaqVQayfEIgrvyua9MiaONXRpShGQSziR02YjX8atMU29KD6dyifcdqgykk403mDzSIzr8QEUVbn9zsW+anoXf7cLqrfs8P7vz3aV4+YsSnP+POeFtqmqhJ6McDhBRW1gKjIhOAKDHpUYDmeatZJI5a7abFkEpfoXfPvlGXwCgLrxur9g07cHfhPYvJlLE0xQGXdotJ1IUAx+YiuN+P12ZHADwwriimG2vfLkB73xdin/OWhvz2QOTluOif36B0Q6TkfMyzV4dyty8ZY/6FD/JKIfbAEwC0IuIPgfwCoCblUqlEaLQX1WN+WI/OrBvtJ4FscVI7p+0TKss7nz7qvHzQ19Sqmask2lBT+4OW6V0idw6vTrG2hKpYZE5M8R4dWL+/dWGmG0vf1ESs42Z8fq879Dn7o+0ei4lVA7M/DWAUwGcCODnAI5mZlV+cNohIjDrraUAhB7M1gYqotn0bBc73f227IBWGZyPcNk+DTZUnw5L1bQ8E+hlDQLsQZCTBRt24fO1amaL5HpzZr/2UZ+rCkgkx9UM+rpe8tQX+GBJcokabQXVzEM57D0UMicdOBxtnS/d5e19dLi6Bg/+bwUOV9doLWecjLfSjwBcBeA4AMcCuNLaJtSSFo3NKQe/Z1NVAj57wHNqn0hhJqcM102cr6RdIHlTR31kkMOV0330f5m2Glc/PzfQ9vwWpN2j+eINu1CyXc1gxH2ZZ/7mtLj7V7k63JmrtnlGUC/YsAs3/Wchvvh2u+dzMqBzbN3sRnm5MduemhVbz2LjznKM9QnMG/rIDBysDCkSnWuFyZiVjnf8nQzgAQAXKpQpazDZVfnN+lVHaDtHUs4ORJVpx4YQPVp1B0d9tqbMSErlFZv3Kvnd8KE4iv2c2Kudkra8cN9fXjOFW15fGGibfma8RObLRz5cGfX+2pfmY8yTn+PLb3d47n/Vc3Nx6xuLYrbbtWFSwV57OfmPM9P2klRlvkzGrHSz4+9nAIYAMBMbX49gNjuS9ZtyX/7sV0qD4xo4UoXrPn6nWemVnwwNv35y5lpc88K8wFNKJKNrzv37Z4G26YSIos7xX68YnNT39ldU4fhHpmPuOu/OMR52R+WeKXg5A1QpyO3lzMSa7O0122FS/mhppIKd02vRPXDwGkSlY8b62SvFKBw/OeXvOdl/SM1sP50I6XIAvYMWJNPQMYp03rzd2zZR3p4TP88dAHh/8SZl7SYqiKISv+Lzhy2zwkYfm29tGdqjTfi1M026Dpyn2MvE4cWyTXtQtq+iVhXb3DMHr4HAnoO1M5GUH67Csk178Oepq8DMaS9IOwNgV7lcSKtr2HOw5BXA2K9jxKzklOCpq4+N2TdIVI3lkllz+B8RTbL+PgCwCgGU7iSiRkQ0j4gWE9FyInrQ2t6DiOYS0RoieoOIlD9N15zQPWabDguD8yY+okWj8GuVKa0j1gb/B2iHwiDAPIdW0j1zSBQEV9vOyo9zBxwRfn3j6Ufil6f1UtKOF/Y5TudUL0ojc2l4zcE5CAChXbOGMftu2n0w5l5ftHE3/jx1Vfh9ZXUNHv1wpWdMwMl/mInz/zEH//hkLUp2hBS7Vw2HRGzYUY4ZK7eGZXXS664PccETc2L6A/c6BQB0a+M9wBveq22KEqXGhh1q1m6SmTk8BuDP1t+jAE5h5vEBtF0B4AxmHgRgMICzrRiKPwB4nJl7A9gFQHmqjg4tYm/cDTvLFXsGcNToytlx3fJasLZYL6KLsUR/tqtcnXJwVqCLN3sJEq9FUq/R5StfblAyY3S2lUNAK41eau7D/LHifD827nvqBh+FOOD+j6Pej33yc/zjk4ib64dLt+CZT9fhkQ9XxHzXGWFeWxfP6yYW+362fPPeGKu+12jdTwG3aqJ2fPuFz9pIbUlmzWG24+9zZg7EMMsh9ltv86w/BnAGgLet7RMBjA2ivXh4dRSnPzYLD38Qe0MGyeqt+8Ovncph1qptStsF3B2Wy/9dwazJ/skGrhGlLogoqZGwimN3dpS267RqvCqyAcADrkyhAHCoshrrA/Yccj9T+bnpjQTshJiV1Yw5a7bjh8/P9U04Zx/z4VoM6vw6ePegwUsZxZud/ePKIWnLlAhVM17fK0ZE+4hor8ffPiIKxMWCiHKJaBGAbQCmAfgWwG4rRQcAlALoHERb8eXw3j5HkQ+4jdMW7VQOOvLhOQ9ZZ3BUucO3O8NSHQEINitupIM2c6DkaDueBOf+7TOc/tisSC6fWpwCP7fhVE2IXnb+H74wF3PWbscvX/06tl1HYqUPloQWlYOMnXnm03VR78sPx2YQijfYyUtTOZrEV2Jmbs7MLTz+mjNzrENvGjBzNTMPBtAFwFAA/bx28/ouEV1PRMVEVFxWVrsANiNJwhhomh9ZIGyguad0Nuc276iMwnQeZX6DzHtgVCjmaHNW7A19qNJsqrJ11qzhwyVbUDh+Mial4JCwtHRPVGBYpbVQ676dKc6lnrd+Z8w2+x70uhW9qzbGbkvnvPo9hX/6eJXPJ47vkvdrr/d1gaSfTiJqT0Td7L8ghWDm3QBmATgBQCsisp3huwDwDElk5meZuYiZiwoKCrx2SRrf66Z4BO+cLejOGOoczd51rksnKzzuoxweHUd3ahn1WSpVslRRXBLbUdWWRB3DUfdO8fWpry3/mfsdgOSS7NkFgF6btzHp37/giTm46T+RNbK7/7sUQLRTRaJF4sue+RKvzt2AiqpIZ15ZzVFrfomeDuZYRZJq5T/m2kUM1MH+Py7JeCtdSERrAKwHMBtACYCPatswERUQUSvrdWMAZwJYCWAmgEut3cYhAM+oROxT5CccD0a0QmigeXXW2WEN7hpdEEWlTnQ/QM6guGdmr4MKUjme5z4LXgZyve7tkanzyue+QvlhdffhwVrOTiqqqnHf+8t8M4naHKoMdegHXWaXJvkN4rrx3v3eMvS9Z0r4fb/7pqD33ZFu5t2FkdmMU4nYvDAnlDbbeV87A++uP6VnXLmBUGT0X6atTrhftpBMj/QwQiP61czcA8BIAEEUYO0IYCYRLQEwH8A0Zv4AwO8A3EZEawG0BfBCAG3F5YmZEe8Ip/+7atO/UyHonHaGRnKRBt0jLhVBcPaCnnsw51QOL39Rgov++bkSL7FkT2+QBZAixxzd+sh+HTz337w7/UybVdU1+HDplsjCqeuipms63V9RhSEPTcVv31qCV77cgD9N/QZ7yis9vbqcys3dXm4OYcG9o9KSwc23ZQewbW/0uXp9/ka4n1jnu9tH90n4uz952d9jKRkyKeFfECSjHCqZeQeAHCLKYeaZCLme1gpmXsLMQ5j5GGYewMwPWdvXMfNQZj6SmX/AzOozsjlwplVQHQhnsuC9s2n3GsPzc9YnHCGmi/sBemhMtPfMwu924/1FySU3U8FnCtKWRx1ynA7EXYwnEf3vm4KzHv8U89bvxD9nfYtfvvo1Pl4eSYUdzwaeLKu+34td5ZWYtDh0TUp3HcSgh6bi2U/XRdn0K6qq0f++iFtqUP2kn4eZV8Di9v2Hw2Y0IPq+btggFwXNY13WVeFenK6LaiOZu3E3ETUD8BmAV4nobwD022E04RzxlOxQF+vAzNoXoZ04H16vyNk/T0u8AFfbdomA0UcfEbPPb95arKRtUyQ7xqiqYZ/FVm/KD1dj1dZ9uOyZL/H6vFCnuOOA91gqld914jZ3btoVWheavnJrVAoJ25xkE9Qo+l8eaa2B5M6pewbcOMkIcSFEPFfWJ4hoBIAxCKXMuBXAFITcTS/QI55+3GlzX/68RFlb8ab6MxXHOjjD/70emvpYX/re8/sbadd5LuN1mac/NgvDH52BwvGTw1lBD1RUYcqy7xO2sdkq/uLXaaZ7OVduifZadwaeOX9yuSvXkHudJWie/yxxaU73Mdczq49y4s0c1iAUHb0cocjoAcw8kZn/bpmZ6iXumgb7DqlLkRtv5nDtS+pSWAOIMt3ofmjs9nTXUdiTZOT36MdnB9pudQqFpLZZvvkfWgngfvfOEvzi3wuwxpXzJ1WTZ7om0vHvLo16b9cen7y9Sj0AACAASURBVF+yK6oa2VWu1N9+A58pt56clhwxv7M8scL8zidYThWmdE/XNo0T75QG8eIc/sbMwxEq9LMTwEtEtJKI7iWixKs7dYirhgXqmZsUjOhUEl7TcNvOG3S7JnC2q/shsjvGtxYkF9y/euv+QBbl7V/o0jqScydpRWztt8HKGWSb2r75fi+Y2Tcqll3/fz92AAA18Rvx0rz4HedRRwQSIpUWqu+7eGuIKherVS2NJpM+YwMz/4GZhyBU9OdihFxO6w1nedi9wyi8qImqYU34UM1pdreqNY0FDHl1UGp29yCfN6LYWWLfDs3jfmfH/sM4UFEVToG9uHQP3ltYirP/+hneWlDqfw452oRlt6uzvGSmMnaI8mQLYXTe4saUAxHlEdEFRPQqQvENqwFcokYcM8RbF1Z5jROtR1fX0wfaPux4D1BFVXWtR+8bdhzAhI++CXf0F7k6hz4dYuMNbOzONKjo5XB2VOvoE3VUby8oxQVPzInK1f/rN6zZw5Z9vuZO9xmz23XeSi9fe7zyNNLpLoAHwTBHWhonvxrZO2FVOFWo7EdUeVXGW5AeRUQvIpTf6HoAHwLoxcyXM/N/lUhjCKd9tKWrdKeqEUAy13PrXj1evF7HqFIvJXNO+94zBQ9PTj/x4btfl+LUP83C07O/xXprHensAdEzxFvP9LeO1jDj27L9OOreKXg7SXNUPNK5j9aVHQinonay80AFTvvTLM/vuK+b3a5z5nBa3/Y4Z2DH1AVKAWe8kO6Z4vGF3sqBiNCjXVP0TFAZTgWdW6tZFwDUmYrjzRzuAvAlgH7MfAEzv8rMeivQayJuThSFOj+Tg2Z2HVCXtts+p/bRd27l/eC86vBZT5Xb3oy4w9odoztFyYgj/ctm9r1nSngReKrH4uc7C0ox/NEZSc9ualNXwc1/F2329SZzjyK9Zg466OpT20AHCc+xgceuX8cWePHHRUp+W1XqnXgL0qcz83PMHHyymQzDafuPsccb7r+XbdqD6Su2Jt4xYPZVpOaldfd7S8MFUxLhTqn8gt9Dk2SH9sGSzZi3fie+33MIheMn4ytXeUu/ovctG+fFTelgK+/yw9UxC8C3v7UYW/Yciuvy6+yQdYa0rN66D9usWWduBq45/DyJVBa1waRJy8brcvdsFzJjtmuWfn0Hr/vIWfI2SDIvLaYBTEQqe9kJbznjyJht5/9jDn76Su3C+qPbTW6/z9fuSOkhe3Xud3ELpni1a/fVfh4syaZBu+k/C3HZM19i7vqQUrDz7NjUMIPgPcJq6kjf4ebn/1oAIJS6fdCDU8PbX5vnHYXrZEnpblzy1Bfh95E1B7UwgNGPf4rv9x4CEXmalUxTqNiso7OYUip0ad0Yp/ctwDPXpD+DeOqHx8Vs61ngv3ZWG0Q5IFobD3UtZulSGwTgttF99bSV5HRISUW4FKZi6fZn01wzLXth38v3Pp2Z4Z0O3/9bXluIn7wciUn515clKBw/OUpBHa6qwT6FpV+dLC2NDkazjzkDBtNhVD9TlxV1jft5p5YRM+b7N45QLE2EBrk5eOnaoTiue+u0fyOuZ2XAiHJAdGd5rmuhTtmCtJqfTQu/Y0zkaquaqhqOMRGlwzprQdrrcFI5QueMwWbqiq345JtINPvDk0Pux84U2VExHopPqTN7KQBUpRCApwrdtQ0SWQKcVdka5AYjzK/jODfUVUQ5ILoTdBdCV7loHMRPF46fjGtfmpfy9y4r6pJwH9XmtmTO7RXPfmVcBps7XdHCXthK4SNHygtm4KgjouMadOTV2neoEh8uTRxJrBu3k8eaR84J+Pfj07ppPnoWhExbQRX66tSqUWpCOHBbK0Yc2TYAiWqPKAfEv0GedKTzzlRmrkq9Ep7Tz94/oCpdiYLlux3leGDScmzYEd9Z7ttt+30/27LnkOfzGlQXPfrx2b4xEcwcUybymuHdccmxiRV0bZhfskt5ZuF4NMn3TnTXv1P0GlOQJTSvOL5rUgr/jeuH4+Vrj4/77NsKJBm6peiddeXQiOlrzOBOUZ9dcEwn9+4AgEX3Rac8/+Dmk/CwFQGvAlEOcLmyuj4rP1yNwvGT8ZGV6yYwND+zd7y9GNe9PD+8yOu2TXsR1CJmZXUNfvnqgpjtyXbM01duxctflERVHPPi75/4K/JDldXeZqUUtcNqV46jyPb9YfOVmxqOmC/sUXOjvFz8+bJBqTWeBi0b+3vGqA6E85sdDejcMlxg6qUfHx9om8zJ3VcFzRvitL7tY0f8Fp/dcTpG9/e37w/sHF3FcFjP6NF+Ihf4R8YODL++amg3fHbH6eHZvN892apJ9LUc0Lklrjmhe9x2aoMoByQ3tVRRY6A2MRR7yiujSjEm4s3iUsz4ZhsmfrEBhOgC6QTvaGG3amBmfLamzLeD9GPppj2YX7ILAKIifpPloQ9CwXDb96cfFOin5lI1G45+/FPfz77f613mtJrZ2PrNzR4ecDaqA+HindsWVrBp0KeFwSn9ZvNGeSiZcF5MYFzXNk3i/s57vzwx7u8mkiEnh5BnDxiI0LVNk7ADBoFQMuG8hLKrRpQDgKiU9T4XVdezneezQLanvDIqMG3QQ1Nx3MPTUv59P4Xy1i9OxIe3RGfMvOSpL8LlHj9dXYYed36Ia16YF7eDBIDX532HwvGTw2YWp2ljf4rxE36y700xW25IBA9vpbSlieXlLzb4tM2RAYhmHdEwz9wjnmPgkEMzh9Rb9Fpfc285xxFhnyjwLBkJltx/FpY/eFb4vXsA099Rb12l+cgPY3cOEXUloplWptflRPQra3sbIppGRGus/+n7fSVJMqO64Ec43r/fv1PLmH2BkDIY4lIGFUkUjffDHRXesnFejC14/fYD6HdfqK7vdFeAW7yC9X+fsQZAZKTvdqM8s197q+EUhbZ+Z+aqbTjmgal4c/5GvFm8McUf8fzJQPh0tffaTw37j2ZTsWung+606FFtJ/HQ2Of/g5tPwql9CmrdZg2n96zaXxnQuUU4B5f7d35zVsTVPNGxJXPsjfNzo+Js7OzQI3qHIvfHDomsPTjNR7N+cxqm33ZKwt+vLSZnDlUAbmfmfgjVqL6RiPoDGA9gBjP3BjDDeq+UZC6kiofMq9kJFw+M3aiAVI/Hvfwwb30kcH6tayHYHoXZ36mJKnZDaXuI2LECH1ueQHe8swR3vL0k6e/Ha/aZa2KDi4KipsY/CO69X6r1s0/kFHVEC2+bu+q23R8N6NwS/3fxwFrXJkh3Af7pa47DNSd0x6QbT8Ljlw+2ZIyWskfbaEX+0rXBrpcc2601SiacF04n07+j90CxsF1THNk+flbfIDCmHJh5CzN/bb3eh1Aa8M4IVZ6baO02EcBY1bI4b2LfTlPTAKxfRz357lPpnw9VVseUa7QXqzfsOIAz/zI7vP1fX21AqVVK0t7HL1Oo81wvvHdUUh1D4fjJVjH51PA7XnuzX36nIKhmRo7Pk+ZO9Bg0iQY+X901Ev/52bDw+zeuP0Fb2246t2qMj2+t3YiYkd7MoVdBMzw8dkCUecmt3Nymp9P7tvf9vSC6i5OsGURt0m3UhoxYcyCiQgBDAMwF0IGZtwAhBQLA8woQ0fVEVExExWVlqbtyOklmJLtzf7DRwumOcBItQm/bewjDH52BdWX+bp1A9M2baBZx0h8+idnGANaV7Y8xpfzDMikBwFfrdmDH/gq8vyg6MMvLXtu6aT4+uf20uHLUFq+jtKNVVXbSzjUH3ckWk2muj6O2RJAJ8+I1rcpZj5mDm+V7nLyOLZObaQV1mWf/9jRMv+3UYH4sRfwTy2iCiJoBeAfArcy8N9mHh5mfBfAsABQVFdXqXksmq+GXAUTqulHRTXywZAu27DmEV77cgAcuPBoA8DuX6YUotZt3u4di/GbLXox7MTb4zi5zCQC/e2cpgOjAMWfbbhmC9Hd346eLHxxzNH48ohCdFM4cQnZwM7b/VEx4TfJzAzkPr/0sNPuw18RSOfRkOvae7Zpi1NEd8MzsdTGfpTtz8JYllsm3nIyyfYm95oJSUN3b6k8vbmN05kBEeQgphleZ+V1r81Yi6mh93hHANr/vBydH9Gt3URibmhrGP2et9S3R6MdX63bg7zPW4LlPY2/mdFi7zd+V1D4WZsbijbuxeus+vJFg0Tadh+nRj75J/UsWqlIMJ8Krg27YIBdHHdFCadbUGmYjnjupttcozztoDUBKNRCG9wr5/Md7Tn59Zm+0a9YQx3aL9jdJ5l780fDuuPOcfp6f3TaqT2DneNyJhTitb2iR3HYJbtM0H30d0e7HF/r4y5jzAwgMYzMHCj2pLwBYycx/cXw0CcA4ABOs/++rlsU9uvK7QWet3oY/TlmFtdv24y+XDU76950pIH5mpStOd6rDzHFTStiiM4AxT37uu9/Ifh3w2NTVaUqRPoTgUhYEicqRfU0NGzvmoNq9dkQh7n1/eUrfad+8YdRM0smQbq1RfM+ZSf3O0MI2yG+QgzlrtwMArnYFft1zXj/83spp1b1t08BSdrdpmo+Xr42fDvutX5xoNApdJSZnDiMAXAPgDCJaZP2di5BSGEVEawCMst4rxfkAxXuUFn23GwBQXhFM6ch4kdnxOFQZ60b6xdrt2F1+GA/8L3H1tMpqjgr3d7Y96Sb1WSp1pa92Y0ol1bDD599DiPl3R3eSPzyhW3CNB3TQXt1fIs+6jmmYqNzn5+ExR+OV64bikuNCs/kxgztFmR9P6VOAn57cE8//qAif3B6yzWu/rwLK9ptpGJs5MPMc+F/HkTplifEk8RkI2OkZyuPUFd6w4wAKmjdEk/z4pzbdwcbBymrPRemrnp8b5XFjewz54WfaOaZLq/QESwFDVqWED+yvz+yDx6cHP5uqruG4M5OC5tHJHoMaiA7onJy5LNnLcd7AjphXsjNsc7/8+K7448ersNOnaqAdz5nK8bj3vWZ4oa+syx88C/kNQg/vmf07RPbJgI45A0SoNRnhrWQa99Q70b3sF+wEAKf+aRb63/dxUu0SEa4dUZjUvjZDH5nh+9mm3RGF4Ewj7d22801KItQOIgRZMjNIWjdV47GUQ/FnDm7SsYq0bJyHM46KduzLJUrKXGYPFFrHKZLDDDx59bGYd1dk3EZEOLqTv+t1bU11ztgTLwXTtGEDTyeGTCi/mwky1BZRDnCZlYgCsSF+m8CV1EZH6mYvTNr9TVTeAxJ7kKgqL3n2gI5Jn+9fjeyNdFakbh/dB787+6jojURJzRxaNcnHIxcNwCvXDUu4byqdnnP9K1nszn78OUdFFbaxE/VdMMg7Y6kQPKIckJ6Zo3D8ZFS5aiE7lcrBw/HXJezsqA08Rj6/OLVX6gKliCnlcKCiKuNmDDZBKIdRDvOGzREtG3kG/nnx61F90jIrXXNC9ygvmlBbybtUXj2se9gs+c4NkaRyPxoem/XzxycW4rdWKol4skY855ISAUBoFlMy4byYZ6BnQTOUTDgPI/vFnt9MJENv8ZQQ5YDYkax9LyeKmp2yPLqQivMhiPdAVNcwDlXWgOA9cxh/zlFYfN/ouG3XlnhR4Xecra5c6atzN+A/c0MV1Q54LOx3bxtcEJabREqpKgDlcOlx3jUaUlGI6SgHv0XRdBSxVxlL58DngQuPxo2n+2d7jffdbCFTB0CpIMoBbrNSZHuiEoJV1YyDh6vx9OxvsXrrvqjp876KSkz46BsUjp8c871XviwBEEog18BaDXf3Sy0VF0mPZx4Y1kNdJSrn6DzVzKqqsWVLdR3ISU0N44EL+sdsT2Wm5q6jkW7dhRxKP4+VzZjBIS+hk9NIimffY9mnGswmPAwK4xHSmYCfWSnRg7WkdA9ufWMRAOBPH6/CNw+fHf7sjreX+HoMTVocqg2xdtv+sAIyWes39jDVPc6V1ZHf9jq/JgeZ9qxlUC08tsoPV+PUvu0Bl0uxnZwwmZoUzlOw8N5ROFwd/97wqyhHSH8E++bPh2P99v04rnvrpGsL3HT6kTjRUeIyvOaQhdpBZg71BHecQ6ToRnxe/Hx9+HV1DUeN+PwUwz9nrcVCK16CKFLwo6o6c54gXQ+zqQI4fpw3sCP+e+OImLKNqVDD7HnfrNiyFwAwO46nm43TrNO6aX7C63HXuUd5bidKf21paI82uPz41OItfnNWX5zYq11U+0BkfU2oW4hyQBwtn+Jz5Vcm0skfp6yKep9rmZWCsHeni/swdUni5bWksiNJ1E8SEQZ3bRXX5Pb0D+ObeHKIwnELp/ctwIzbo5OmJaN4rzi+a9R79zmZ+JPoqF0/BUAajBt2/i6/9gFkp12pHiBmJcSOYNO9l8/522cpf8eeOVQmMB1kC5lugujSOv6COVHI/742ZR7dysl9Tpo1zMURLRrh+72HAMSZHaS5IJ0KR7ZvhkcvHhjXFJfhlzRQiKxqdJk1KU4LmTnAf0Fa9fUNeStZM4csNCt5dRu/Ga3OUyqdwCR3reAOruI4PVwJ6bw8fWqLV0EeOyEcADTKjzzGT1w1JPw6tOagvpe6cmi3mCqCQHqurHUdCv+v+9pBlANitbzteqf6wYpXPlInsSNVdU/zVcO64cbTQz7sXqnAx/pkxA2CVE61nYV0SLfWWPpAxK24oHlDFN9zJqbfdgoGdm6J/94YykXVvnlDlEw4L2GK5XTMZjk5hHvO885Ces95/dCwQSSb6vnHdML9lreU6XsrG9ccMjGpZLqIWQkenaP1X3Ugbw07o0gz5wFSKckZfdvj15aH17QVWz33GTe8O6at2IrNew4plCQ+H916MmwHMneerHbNGqJds4b4380nAQi5mh7TVX1OKpvcnJxwcSJ3XiYgUpg+UX4v1dij56yaOdQjhSgzhxgIN5zaC22a5uNCDaH68abegzR1OG4dqLJkJlFi5fPgmAGY87szMOP2U2tluweiC7OnQsMGuWicHxqRJxojnDOwo9Jz5mZQl5b49ag+uPf8/rjgmNh79PjCNrj1zN7446XHaJPJi0hHmT1cPSx0vzXwqwtbh6j7R6CAAZ1b4ut7R+GXpyUfBZou4dGVx2fv3nCix1b1dG3TBOcf0zGw32veKDKCTXbWnZND6FXQzPOz//w0cQ4gm3vOj5hj0u2kgrQUnBonmCzeeoV9Dm8f1QdEhEZ5ubjupB6eHl85OYRbz+yDds1iZxU6+c3ovujetgmO7aZvVmWa+87vj1W/P9tYQasgEbOSC2dHoCVBXJzsZLpuMK/O75aRvfHBki2B/P4fLzkGbxRvxKxVIR9/dwRwqtRwyMurMolF/Bwi3HBaL+RQ+mspQaw9/eLUXnh69rc432OkDwArHjor7mjz0uO6orKacVlRV999Mo1BXVth9m9PNy2GVnJyCA1z/Cvq1SVEOSQgPzcnYYRqbUi05vDwmKMxd/3OwDrqZHEWna8tTiVHoFrboGuYk06SR0A4W+nGneW1a7gW/Pasvrh6WDffGs2J1gdycwg/TNNEJgjpYLqG9ItEtI2Iljm2tSGiaUS0xvofvG9gCqheWArnn/Fp5prhhbjrXG9PlcBkUOx2554B1fac1jDHrXngjBh2eo/UZsZy1tEd8NKPj0/7+7k5hK5t1CUVFISgMb3m8DKAs13bxgOYwcy9Acyw3mvD3U2qDlxOplu2q13p5o+XHoO7HYpp7l3eBfri2dGBUCGaRy8eiCuHdsVJvduFR895CRIb2txwWnT6Zr8+/uIhnfHABf1x/SmR/Z0Wodpcy2euKcLprmI6Kjn/mI4Jz6sgqMSocmDmTwHsdG0eA2Ci9XoigLFahXJxx1nqgrKA5Dw6TC0sXlbUFT87pWf4vTsAzKZF4/gZZIsK26Bjy8Z49OJjkJebg3vPD/nhH9stuUlhnw7RC9N+M4A7zj4KPx7RA0CkqplzvaAupY5+4qpjY9JkCKmRTQvhKsjENYcOzLwFAJh5CxF5DteI6HoA1wNAt24BFmR38fNTe+HTNWX4fO2OwH/7zH7tccAqCrRs057Af791kzzsKk8iLXaCAfyd5xyFYT3903g3zY8swN02qg/+Mi1+HeZGVtDWwTi1uJ2MHdwZvds3x+PTVmPGN9tQw6HZyJ6DlRh5VHs0yCU8c01R1Hf+e+MIzF0fPe4wmL5K0MzCe0eFXZGF9MhE5ZAUzPwsgGcBoKioKLDHXmft1yeuOhbj31kCAKioytzcSj93VOVq2TgPbZvlRyUZdA7Ikzl767aH0lcvKU1OIRIRBnRuiRtO64XP1mzHcd1bY9JNI1BcsguX+BTX6d62qUe0smiHbKF103zTItR5TK85eLGViDoCgPV/m2F5wp3fqyn41ydDo7zclN1lP3Fl+WzlKgp0Zr8OuG1UHwDJj5RT0YeL7x+NT24/DfPuGonpt52KS4/rElU5Lpn1kXKPCnDJUFTYBqsfOQdtmuaje9umvorBD5k5CELyZKJymARgnPV6HID3dTbu1U/aNm4Vc4pUc7H0dASGvfWL4fjXT4bhqmERs9rz44pwnhXAVuPqDdc/em4tJI2mfYtGOLJ9Mzz2g0Fo61gT6d+pBQrbNvEsf2pjKv1MQ0ML+6Z554bhmHzLSabFEOoYRs1KRPQagNMAtCOiUgD3A5gA4E0iug7AdwB+YE5CFwF2auOswu3JFry5/4L+eLO4NPz+wkGdcHxhGwDAwC4Dw3WZgYjCcc5K2jXL9zWZBdlXD+zcErOswCevEqlO+XSTKClefeW47m1MiyDUQYwqB2a+0ucjb59JQ9gBV0F2anZAU7JmpWtH9MC1lifOiofOisrE6cb+yZaN8/D7sQNw82sLfUtJBkWDHEJVDaNVk4it9/HLB+HrDbt95RMEIXOpswvSqvDq/w9baRryG+SgcV5u0l42bi4e0hnvLtwEIGL/zk3D0pEomtYOaqthxgWDOmFkv/ZhDyHP/QNQelNuPRnFJbuitl00pAsuGhKrlOpD3hlBqO9kpxE2RWzbfX5uDr66cyT+d1Pq9tvrTuoRVRDFXscIcjZiZwZ1Z3ptkt9AeZ6oI9s3xxVDk3MpbmwpN/diuiAImYMoBxdeqST+fuUQ/PjEQvTv2AItm+SFc+i398il78QZ4WoHftkErRzm3jUSU249OfSbOXZKjsx2zzmjr76IY0EQUkOUQxL0aNcUD1x4dLjTtTv2ROaRX7rSPjjhsFkpGOXQoUUjNG9kRQVb2xK5btoeRbqNPGGlZcC6dPWwbsbSkQhCXULWHNIg0QL1lFtPRnUNhyty2TgH8vZnKuzvtlxeCe7aNs3HjgOh8pwNckOLyLqxWzRRZ/eRiwbikYsGam9XEOoaMoSyOOqIUIrqZDKGhk1COcCs35wW9dkPT+iGo45ogaM7tfRd6P2po0jL0MLg3Qwb54UWnwd2bhnz2Ye/OjlcLCfPqh9gQkEIgpDZyMzBwg6QSqaftPfJy8lBYbuI7/xfLx+MsUM6R+3brllD3DLSv6LcyH7B291bNsnDf28cgd7tYyupdWjRKJxA78Qj2+Lj5VvjBqyp4MJBnTBv/c5wnQVBEDIPUQ42FL2eEI/Ctk1w3Uk9cPWwaO8crzKPxfecGX7tNStRlctpcBL1p/92xRBs2FGOpg313gaN8nLx2A8GaW1TEITUEOVgkRN2/0ysHIgoyvto8f2jUVFZjfY+Ka1jv5+WiIHTKC8XfY8IruKbIAj1B1EOFjnhmUPq323ZOA9IUNNAEAShLiEL0hb2zMGdrC5IMjzsQBAEIYwoBwuqxcwhWcIunJliVxIEQfBBlINFKmsOtUVUgyAImY4oB4varDkIgiDUN0Q5WOTmJO/KKgiCUN8R5eBCpXJoYhU81x1XIAiCkCrSS1mE8xEpnDhcObQbyg9X49oRheoaEQRBCICMnTkQ0dlEtIqI1hLReNXthV1ZFWqHvNwc/OLUXnGruAmCIGQCGakciCgXwJMAzgHQH8CVRNQ//rdqhyxIC4IgRMhI5QBgKIC1zLyOmQ8DeB3AGJUNums1CIIgZDOZqhw6A9joeF9qbQtDRNcTUTERFZeVldW6QTv2INOrpwmCIOggU5WDV5xYVK/NzM8ycxEzFxUUFHjsnhpiVhIEQYiQqcqhFEBXx/suADarbFDiHARBECJkqnKYD6A3EfUgonwAVwCYpLLBn5zUAwAwtEfwldkEQRDqGhkZ58DMVUR0E4CPAeQCeJGZl6ts87jurVEy4TyVTQiCINQZMlI5AAAzfwjgQ9NyCIIgZCOZalYSBEEQDCLKQRAEQYhBlIMgCIIQgygHQRAEIQZRDoIgCEIMohwEQRCEGEQ5CIIgCDGIchAEQRBiEOUgCIIgxCDKQRAEQYhBlIMgCIIQgygHQRAEIQZRDoIgCEIMohwEQRCEGDI2ZXc28YdLBuLI9s1NiyEIghBGlEMGcPnx3UyLIAiCEIURsxIR/YCIlhNRDREVuT67k4jWEtEqIjrLhHyCIAjZjqmZwzIAFwN4xrmRiPojVC/6aACdAEwnoj7MXK1fREEQhOzFyMyBmVcy8yqPj8YAeJ2ZK5h5PYC1AIbqlU4QBEHING+lzgA2Ot6XWttiIKLriaiYiIrLysq0CCcIgpAtKDMrEdF0AEd4fHQ3M7/v9zWPbey1IzM/C+BZACgqKvLcRxAEQUgPZcqBmc9M42ulALo63ncBsDkYiQRBEIRkyTSz0iQAVxBRQyLqAaA3gHmGZRIEQcg6TLmyXkREpQCGA5hMRB8DADMvB/AmgBUApgC4UTyVBEEQ9EPMdd9cT0RlADak+fV2ALYHKI4qRM7gqAsyAiJn0NQFOXXL2J2ZC7w+qBfKoTYQUTEzFyXe0ywiZ3DUBRkBkTNo6oKcmSRjpq05CIIgCBmAKAdBEAQhBlEOVqxEHUDkDI66ICMgcgZNXZAzY2TM+jUHQRAEIRaZOQiCIAgxiHIQBEEQYshq5UBEZ1t1I9YS0XjDspQQ0VIiWkRExda2NkQ0jYjWWP9bW9uJ0JkjVQAABXFJREFUiP5uyb2EiI5VKNeLRLSNiJY5tqUsFxGNs/ZfQ0TjNMn5ABFtss7pIiI61/GZZ90QlfcEEXUloplEtNKqZ/Ira3tGnc84cmba+WxERPOIaLEl54PW9h5ENNc6N28QUb61vaH1fq31eWEi+RXK+DIRrXecy8HWdmPPUAzMnJV/AHIBfAugJ4B8AIsB9DcoTwmAdq5tfwQw3no9HsAfrNfnAvgIoUSFJwCYq1CuUwAcC2BZunIBaANgnfW/tfW6tQY5HwDwG499+1vXuyGAHtZ9kKv6ngDQEcCx1uvmAFZbsmTU+YwjZ6adTwLQzHqdB2CudZ7eBHCFtf1pADdYr38J4Gnr9RUA3ognv2IZXwZwqcf+xp4h9182zxyGAljLzOuY+TCA1xGqJ5FJjAEw0Xo9EcBYx/ZXOMRXAFoRUUcVAjDzpwB21lKuswBMY+adzLwLwDQAZ2uQ0w+/uiFK7wlm3sLMX1uv9wFYiVBK+ow6n3Hk9MPU+WRm3m+9zbP+GMAZAN62trvPp32e3wYwkogojvwqZfTD2DPkJpuVQ9K1IzTBAKYS0QIiut7a1oGZtwChBxZAe2u7adlTlcukvDdZ0/MXbXNNHHm0yWmZNIYgNJLM2PPpkhPIsPNJRLlEtAjANoQ6zG8B7GbmKo82w/JYn+8B0Fa1nG4Zmdk+l49Y5/JxImroltEli/ZnKJuVQ9K1IzQxgpmPBXAOgBuJ6JQ4+2aa7DZ+cpmS9ykAvQAMBrAFwJ+t7UblJKJmAN4BcCsz7423q488puTMuPPJzNXMPBih9P5DAfSL06YROd0yEtEAAHcCOArA8QiZin5nUkYvslk5ZFTtCGbebP3fBuA9hG70rba5yPq/zdrdtOypymVEXmbeaj2YNQCeQ8RUYExOIspDqMN9lZnftTZn3Pn0kjMTz6cNM+8GMAshO30rIrJr1TjbDMtjfd4SIVOkFjkdMp5tme6YmSsAvIQMOpc22awc5gPobXk25CO0QDXJhCBE1JSImtuvAYwGsMySx/ZKGAfArqA3CcCPLM+GEwDssc0SmkhVro8BjCai1pYpYrS1TSmudZiLEDqntpxedUOU3hOWffsFACuZ+S+OjzLqfPrJmYHns4CIWlmvGwM4E6H1kZkALrV2c59P+zxfCuATDq32Kqsj4yPjN47BACG0JuI8l5nxDKlc7c70P4Q8A1YjZKe826AcPRHyllgMYLktC0L20BkA1lj/23DEA+JJS+6lAIoUyvYaQiaESoRGL9elIxeAnyC00LcWwLWa5PyXJccShB66jo7977bkXAXgHB33BICTEDIFLAGwyPo7N9POZxw5M+18HgNgoSXPMgD3OZ6neda5eQtAQ2t7I+v9WuvznonkVyjjJ9a5XAbg34h4NBl7htx/kj5DEARBiCGbzUqCIAiCD6IcBEEQhBhEOQiCIAgxiHIQBEEQYhDlIAiCIMTQIPEugiDYEJHtdgoARwCoBlBmvS9n5hONCCYIASOurIKQJkT0AID9zPyYaVkEIWjErCQIAUFE+63/pxHRbCJ6k4hWE9EEIrrayuu/lIh6WfsVENE7RDTf+hth9ggEIYIoB0FQwyAAvwIwEMA1APow81AAzwO42drnbwAeZ+bjAVxifSYIGYGsOQiCGuazle+KiL4FMNXavhTA6dbrMwH0D6XXAQC0IKLmHKqhIAhGEeUgCGqocLyucbyvQeS5ywEwnJkP6hRMEJJBzEqCYI6pAG6y35BVR1gQMgFRDoJgjlsAFFnVwFYA+IVpgQTBRlxZBUEQhBhk5iAIgiDEIMpBEARBiEGUgyAIghCDKAdBEAQhBlEOgiAIQgyiHARBEIQYRDkIgiAIMfw/VudYef3INrAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_series(time, series, format=\"-\", start=0, end=None):\n",
    "    plt.plot(time[start:end], series[start:end], format)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.grid(False)\n",
    "\n",
    "def trend(time, slope=0):\n",
    "    return slope * time\n",
    "\n",
    "def seasonal_pattern(season_time):\n",
    "    \"\"\"Just an arbitrary pattern, you can change it if you wish\"\"\"\n",
    "    return np.where(season_time < 0.1,\n",
    "                    np.cos(season_time * 6 * np.pi),\n",
    "                    2 / np.exp(9 * season_time))\n",
    "\n",
    "def seasonality(time, period, amplitude=1, phase=0):\n",
    "    \"\"\"Repeats the same pattern at each period\"\"\"\n",
    "    season_time = ((time + phase) % period) / period\n",
    "    return amplitude * seasonal_pattern(season_time)\n",
    "\n",
    "def noise(time, noise_level=1, seed=None):\n",
    "    rnd = np.random.RandomState(seed)\n",
    "    return rnd.randn(len(time)) * noise_level\n",
    "\n",
    "time = np.arange(10 * 365 + 1, dtype=\"float32\")\n",
    "baseline = 10\n",
    "series = trend(time, 0.1)  \n",
    "baseline = 10\n",
    "amplitude = 40\n",
    "slope = 0.005\n",
    "noise_level = 3\n",
    "\n",
    "# Create the series\n",
    "series = baseline + trend(time, slope) + seasonality(time, period=365, amplitude=amplitude)\n",
    "# Update with noise\n",
    "series += noise(time, noise_level, seed=51)\n",
    "\n",
    "split_time = 3000\n",
    "time_train = time[:split_time]\n",
    "x_train = series[:split_time]\n",
    "time_valid = time[split_time:]\n",
    "x_valid = series[split_time:]\n",
    "\n",
    "\n",
    "\n",
    "plot_series(time, series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 20\n",
    "batch_size = 32\n",
    "shuffle_buffer_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "x_dataset = x_dataset.window(window_size+1, shift=1, drop_remainder=True)\n",
    "x_dataset = x_dataset.flat_map(lambda x:x.batch(window_size+1))\n",
    "x_dataset = x_dataset.map(lambda x:(x[:-1],x[-1:]))\n",
    "x_dataset = x_dataset.shuffle(shuffle_buffer_size)\n",
    "x_dataset = x_dataset.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataset(a):\n",
    "    x_dataset = tf.data.Dataset.from_tensor_slices(a)\n",
    "    x_dataset = x_dataset.window(window_size+1, shift=1, drop_remainder=True)\n",
    "    x_dataset = x_dataset.flat_map(lambda x:x.batch(window_size+1))\n",
    "    x_dataset = x_dataset.map(lambda x:(x[:-1],x[-1:]))\n",
    "    x_dataset = x_dataset.shuffle(shuffle_buffer_size)\n",
    "    x_dataset = x_dataset.batch(batch_size).prefetch(1)\n",
    "    return x_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = to_dataset(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = to_dataset(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, LSTM, Bidirectional, Lambda\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs=tf.keras.callbacks.LearningRateScheduler(lambda epoch:1e-8 * 10.0 ** (epoch//20*1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Lambda(lambda x:tf.expand_dims(x, -1)),\n",
    "    Bidirectional(LSTM(64, input_length=window_size, return_sequences=True)),\n",
    "    Bidirectional(LSTM(64)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=Adam(lr=1e-5), metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     \"\"\"\n\u001b[0;32m   1345\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1346\u001b[1;33m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[0;32m   1347\u001b[0m                        \u001b[1;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1348\u001b[0m                        \u001b[1;34m'`fit()` with some data, or specify '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 662.1749 - mse: 662.1749 - val_loss: 990.1065 - val_mse: 990.1065 - lr: 1.0000e-08\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 662.1478 - mse: 662.1478 - val_loss: 990.0703 - val_mse: 990.0703 - lr: 1.0000e-08\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 662.1208 - mse: 662.1208 - val_loss: 990.0342 - val_mse: 990.0342 - lr: 1.0000e-08\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 662.0941 - mse: 662.0941 - val_loss: 989.9979 - val_mse: 989.9979 - lr: 1.0000e-08\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 662.0671 - mse: 662.0671 - val_loss: 989.9622 - val_mse: 989.9622 - lr: 1.0000e-08\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 662.0404 - mse: 662.0404 - val_loss: 989.9259 - val_mse: 989.9259 - lr: 1.0000e-08\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 662.0135 - mse: 662.0135 - val_loss: 989.8896 - val_mse: 989.8896 - lr: 1.0000e-08\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 661.9863 - mse: 661.9863 - val_loss: 989.8526 - val_mse: 989.8526 - lr: 1.0000e-08\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 661.9593 - mse: 661.9593 - val_loss: 989.8168 - val_mse: 989.8168 - lr: 1.0000e-08\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 661.9323 - mse: 661.9323 - val_loss: 989.7806 - val_mse: 989.7806 - lr: 1.0000e-08\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 661.9055 - mse: 661.9055 - val_loss: 989.7437 - val_mse: 989.7437 - lr: 1.0000e-08\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 661.8782 - mse: 661.8782 - val_loss: 989.7076 - val_mse: 989.7076 - lr: 1.0000e-08\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 661.8514 - mse: 661.8514 - val_loss: 989.6714 - val_mse: 989.6714 - lr: 1.0000e-08\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 661.8246 - mse: 661.8246 - val_loss: 989.6353 - val_mse: 989.6353 - lr: 1.0000e-08\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 661.7975 - mse: 661.7975 - val_loss: 989.5989 - val_mse: 989.5989 - lr: 1.0000e-08\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 661.7706 - mse: 661.7706 - val_loss: 989.5630 - val_mse: 989.5630 - lr: 1.0000e-08\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 661.7436 - mse: 661.7436 - val_loss: 989.5262 - val_mse: 989.5262 - lr: 1.0000e-08\n",
      "Epoch 18/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 661.7167 - mse: 661.7167 - val_loss: 989.4905 - val_mse: 989.4905 - lr: 1.0000e-08\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 661.6898 - mse: 661.6898 - val_loss: 989.4540 - val_mse: 989.4540 - lr: 1.0000e-08\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 661.6630 - mse: 661.6630 - val_loss: 989.4179 - val_mse: 989.4179 - lr: 1.0000e-08\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 661.5131 - mse: 661.5131 - val_loss: 989.0533 - val_mse: 989.0533 - lr: 1.0000e-07\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 661.2397 - mse: 661.2397 - val_loss: 988.6879 - val_mse: 988.6879 - lr: 1.0000e-07\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 660.9666 - mse: 660.9666 - val_loss: 988.3241 - val_mse: 988.3241 - lr: 1.0000e-07\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 660.6929 - mse: 660.6929 - val_loss: 987.9570 - val_mse: 987.9570 - lr: 1.0000e-07\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 660.4197 - mse: 660.4197 - val_loss: 987.5920 - val_mse: 987.5920 - lr: 1.0000e-07\n",
      "Epoch 26/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 660.1467 - mse: 660.1467 - val_loss: 987.2275 - val_mse: 987.2275 - lr: 1.0000e-07\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 659.8729 - mse: 659.8729 - val_loss: 986.8608 - val_mse: 986.8608 - lr: 1.0000e-07\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 659.5988 - mse: 659.5988 - val_loss: 986.4938 - val_mse: 986.4938 - lr: 1.0000e-07\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 659.3246 - mse: 659.3246 - val_loss: 986.1262 - val_mse: 986.1262 - lr: 1.0000e-07\n",
      "Epoch 30/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 659.0521 - mse: 659.0521 - val_loss: 985.7597 - val_mse: 985.7597 - lr: 1.0000e-07\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 658.7791 - mse: 658.7791 - val_loss: 985.3957 - val_mse: 985.3957 - lr: 1.0000e-07\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 658.5049 - mse: 658.5049 - val_loss: 985.0293 - val_mse: 985.0293 - lr: 1.0000e-07\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 658.2307 - mse: 658.2307 - val_loss: 984.6614 - val_mse: 984.6614 - lr: 1.0000e-07\n",
      "Epoch 34/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 657.9556 - mse: 657.9556 - val_loss: 984.2913 - val_mse: 984.2913 - lr: 1.0000e-07\n",
      "Epoch 35/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 657.6815 - mse: 657.6815 - val_loss: 983.9251 - val_mse: 983.9251 - lr: 1.0000e-07\n",
      "Epoch 36/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 657.4069 - mse: 657.4069 - val_loss: 983.5591 - val_mse: 983.5591 - lr: 1.0000e-07\n",
      "Epoch 37/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 657.1314 - mse: 657.1314 - val_loss: 983.1896 - val_mse: 983.1896 - lr: 1.0000e-07\n",
      "Epoch 38/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 656.8562 - mse: 656.8562 - val_loss: 982.8235 - val_mse: 982.8235 - lr: 1.0000e-07\n",
      "Epoch 39/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 656.5806 - mse: 656.5806 - val_loss: 982.4542 - val_mse: 982.4542 - lr: 1.0000e-07\n",
      "Epoch 40/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 656.3039 - mse: 656.3039 - val_loss: 982.0872 - val_mse: 982.0872 - lr: 1.0000e-07\n",
      "Epoch 41/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 654.7723 - mse: 654.7723 - val_loss: 978.3861 - val_mse: 978.3861 - lr: 1.0000e-06\n",
      "Epoch 42/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 651.9373 - mse: 651.9373 - val_loss: 974.6855 - val_mse: 974.6855 - lr: 1.0000e-06\n",
      "Epoch 43/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 648.8307 - mse: 648.8307 - val_loss: 970.3129 - val_mse: 970.3129 - lr: 1.0000e-06\n",
      "Epoch 44/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 645.3193 - mse: 645.3193 - val_loss: 965.8871 - val_mse: 965.8871 - lr: 1.0000e-06\n",
      "Epoch 45/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 641.9210 - mse: 641.9210 - val_loss: 961.5974 - val_mse: 961.5974 - lr: 1.0000e-06\n",
      "Epoch 46/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 638.5949 - mse: 638.5949 - val_loss: 957.3209 - val_mse: 957.3209 - lr: 1.0000e-06\n",
      "Epoch 47/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 635.2899 - mse: 635.2899 - val_loss: 952.9872 - val_mse: 952.9872 - lr: 1.0000e-06\n",
      "Epoch 48/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 631.9708 - mse: 631.9708 - val_loss: 948.5389 - val_mse: 948.5389 - lr: 1.0000e-06\n",
      "Epoch 49/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 628.5895 - mse: 628.5895 - val_loss: 944.0042 - val_mse: 944.0042 - lr: 1.0000e-06\n",
      "Epoch 50/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 625.0745 - mse: 625.0745 - val_loss: 939.4179 - val_mse: 939.4179 - lr: 1.0000e-06\n",
      "Epoch 51/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 621.5257 - mse: 621.5257 - val_loss: 934.8612 - val_mse: 934.8612 - lr: 1.0000e-06\n",
      "Epoch 52/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 618.0031 - mse: 618.0031 - val_loss: 930.3300 - val_mse: 930.3300 - lr: 1.0000e-06\n",
      "Epoch 53/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 614.5175 - mse: 614.5175 - val_loss: 925.8591 - val_mse: 925.8591 - lr: 1.0000e-06\n",
      "Epoch 54/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 611.0540 - mse: 611.0540 - val_loss: 921.3675 - val_mse: 921.3675 - lr: 1.0000e-06\n",
      "Epoch 55/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 607.6414 - mse: 607.6414 - val_loss: 916.9681 - val_mse: 916.9681 - lr: 1.0000e-06\n",
      "Epoch 56/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 604.2704 - mse: 604.2704 - val_loss: 912.5838 - val_mse: 912.5838 - lr: 1.0000e-06\n",
      "Epoch 57/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 600.9059 - mse: 600.9059 - val_loss: 908.1989 - val_mse: 908.1989 - lr: 1.0000e-06\n",
      "Epoch 58/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 597.5679 - mse: 597.5679 - val_loss: 903.8459 - val_mse: 903.8459 - lr: 1.0000e-06\n",
      "Epoch 59/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 594.2117 - mse: 594.2117 - val_loss: 899.4593 - val_mse: 899.4593 - lr: 1.0000e-06\n",
      "Epoch 60/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 590.8489 - mse: 590.8489 - val_loss: 895.0771 - val_mse: 895.0771 - lr: 1.0000e-06\n",
      "Epoch 61/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 569.9967 - mse: 569.9967 - val_loss: 841.7469 - val_mse: 841.7469 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 518.1940 - mse: 518.1940 - val_loss: 761.3217 - val_mse: 761.3217 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 461.1770 - mse: 461.1770 - val_loss: 687.3846 - val_mse: 687.3846 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 412.2301 - mse: 412.2301 - val_loss: 622.4854 - val_mse: 622.4854 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 369.2807 - mse: 369.2807 - val_loss: 563.1036 - val_mse: 563.1036 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 330.6306 - mse: 330.6306 - val_loss: 508.1897 - val_mse: 508.1897 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 296.4149 - mse: 296.4149 - val_loss: 458.5157 - val_mse: 458.5157 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 267.0839 - mse: 267.0839 - val_loss: 414.7954 - val_mse: 414.7954 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 242.0399 - mse: 242.0399 - val_loss: 376.4377 - val_mse: 376.4377 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 220.9242 - mse: 220.9242 - val_loss: 342.6760 - val_mse: 342.6760 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 203.2274 - mse: 203.2274 - val_loss: 312.7329 - val_mse: 312.7329 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 188.2746 - mse: 188.2746 - val_loss: 286.4200 - val_mse: 286.4200 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 176.0983 - mse: 176.0983 - val_loss: 263.8653 - val_mse: 263.8653 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 166.0078 - mse: 166.0078 - val_loss: 244.2369 - val_mse: 244.2369 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 158.7152 - mse: 158.715 - 1s 9ms/step - loss: 157.6911 - mse: 157.6911 - val_loss: 226.8415 - val_mse: 226.8415 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 150.9756 - mse: 150.9756 - val_loss: 212.1158 - val_mse: 212.1158 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 145.4197 - mse: 145.4197 - val_loss: 198.9431 - val_mse: 198.9431 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 140.8765 - mse: 140.8765 - val_loss: 187.4211 - val_mse: 187.4211 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 137.3379 - mse: 137.3379 - val_loss: 178.0372 - val_mse: 178.0372 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 134.3027 - mse: 134.3027 - val_loss: 169.6528 - val_mse: 169.6528 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 117.7222 - mse: 117.7222 - val_loss: 109.3267 - val_mse: 109.3267 - lr: 1.0000e-04\n",
      "Epoch 82/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 82.5239 - mse: 82.5239 - val_loss: 74.7109 - val_mse: 74.7109 - lr: 1.0000e-04\n",
      "Epoch 83/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 63.5968 - mse: 63.5968 - val_loss: 60.0307 - val_mse: 60.0307 - lr: 1.0000e-04\n",
      "Epoch 84/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 51.0659 - mse: 51.0659 - val_loss: 50.1853 - val_mse: 50.1853 - lr: 1.0000e-04\n",
      "Epoch 85/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 40.4589 - mse: 40.4589 - val_loss: 42.1842 - val_mse: 42.1842 - lr: 1.0000e-04\n",
      "Epoch 86/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 34.2976 - mse: 34.2976 - val_loss: 40.3906 - val_mse: 40.3906 - lr: 1.0000e-04\n",
      "Epoch 87/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 29.5417 - mse: 29.5417 - val_loss: 32.9749 - val_mse: 32.9749 - lr: 1.0000e-04\n",
      "Epoch 88/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 26.8740 - mse: 26.8740 - val_loss: 30.5137 - val_mse: 30.5137 - lr: 1.0000e-04\n",
      "Epoch 89/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 24.5224 - mse: 24.5224 - val_loss: 27.7859 - val_mse: 27.7859 - lr: 1.0000e-04\n",
      "Epoch 90/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 24.1363 - mse: 24.1363 - val_loss: 25.1517 - val_mse: 25.1517 - lr: 1.0000e-04\n",
      "Epoch 91/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 23.0083 - mse: 23.0083 - val_loss: 24.5928 - val_mse: 24.5928 - lr: 1.0000e-04\n",
      "Epoch 92/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 22.1397 - mse: 22.1397 - val_loss: 24.6135 - val_mse: 24.6135 - lr: 1.0000e-04\n",
      "Epoch 93/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 21.4439 - mse: 21.4439 - val_loss: 25.1610 - val_mse: 25.1610 - lr: 1.0000e-04\n",
      "Epoch 94/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 21.2379 - mse: 21.2379 - val_loss: 24.0601 - val_mse: 24.0601 - lr: 1.0000e-04\n",
      "Epoch 95/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 20.7002 - mse: 20.7002 - val_loss: 22.9505 - val_mse: 22.9505 - lr: 1.0000e-04\n",
      "Epoch 96/100\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 20.3808 - mse: 20.3808 - val_loss: 22.4089 - val_mse: 22.4089 - lr: 1.0000e-04\n",
      "Epoch 97/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 20.4859 - mse: 20.4859 - val_loss: 21.2483 - val_mse: 21.2483 - lr: 1.0000e-04\n",
      "Epoch 98/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 20.0754 - mse: 20.0754 - val_loss: 22.3130 - val_mse: 22.3130 - lr: 1.0000e-04\n",
      "Epoch 99/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 20.4716 - mse: 20.4716 - val_loss: 21.1098 - val_mse: 21.1098 - lr: 1.0000e-04\n",
      "Epoch 100/100\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 19.5824 - mse: 19.5824 - val_loss: 22.4093 - val_mse: 22.4093 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_dataset, validation_data=valid_dataset, epochs=100, callbacks=[lrs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=Adam(lr=1e-5), metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "94/94 [==============================] - 2s 19ms/step - loss: 19.2900 - mse: 19.2900 - val_loss: 20.9168 - val_mse: 20.9168\n",
      "Epoch 2/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 19.1972 - mse: 19.1972 - val_loss: 21.3958 - val_mse: 21.3958\n",
      "Epoch 3/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 19.0872 - mse: 19.0872 - val_loss: 20.8559 - val_mse: 20.8559\n",
      "Epoch 4/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 19.0752 - mse: 19.0752 - val_loss: 21.0669 - val_mse: 21.0669\n",
      "Epoch 5/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 19.0211 - mse: 19.0211 - val_loss: 20.8555 - val_mse: 20.8555\n",
      "Epoch 6/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 18.9699 - mse: 18.9699 - val_loss: 20.8182 - val_mse: 20.8182\n",
      "Epoch 7/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.9164 - mse: 18.9164 - val_loss: 20.8011 - val_mse: 20.8011\n",
      "Epoch 8/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 18.9406 - mse: 18.9406 - val_loss: 20.8057 - val_mse: 20.8057\n",
      "Epoch 9/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.8839 - mse: 18.8839 - val_loss: 20.6802 - val_mse: 20.6802\n",
      "Epoch 10/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.8535 - mse: 18.8535 - val_loss: 20.5690 - val_mse: 20.5690\n",
      "Epoch 11/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.8298 - mse: 18.8298 - val_loss: 20.3706 - val_mse: 20.3706\n",
      "Epoch 12/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 18.8483 - mse: 18.8483 - val_loss: 20.3308 - val_mse: 20.3308\n",
      "Epoch 13/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.8129 - mse: 18.8129 - val_loss: 20.5544 - val_mse: 20.5544\n",
      "Epoch 14/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.7731 - mse: 18.7731 - val_loss: 20.6186 - val_mse: 20.6186\n",
      "Epoch 15/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.7528 - mse: 18.7528 - val_loss: 20.7171 - val_mse: 20.7171\n",
      "Epoch 16/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.7918 - mse: 18.7918 - val_loss: 20.4139 - val_mse: 20.4139\n",
      "Epoch 17/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 18.7089 - mse: 18.7089 - val_loss: 20.6459 - val_mse: 20.6459\n",
      "Epoch 18/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.6712 - mse: 18.6712 - val_loss: 20.3519 - val_mse: 20.3519\n",
      "Epoch 19/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.6464 - mse: 18.6464 - val_loss: 20.4606 - val_mse: 20.4606\n",
      "Epoch 20/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.6541 - mse: 18.6541 - val_loss: 20.6128 - val_mse: 20.6128\n",
      "Epoch 21/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 18.6417 - mse: 18.6417 - val_loss: 20.6328 - val_mse: 20.6328\n",
      "Epoch 22/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.5932 - mse: 18.5932 - val_loss: 20.6439 - val_mse: 20.6439\n",
      "Epoch 23/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 18.5628 - mse: 18.5628 - val_loss: 20.3383 - val_mse: 20.3383\n",
      "Epoch 24/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.6051 - mse: 18.6051 - val_loss: 20.5153 - val_mse: 20.5153\n",
      "Epoch 25/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.5622 - mse: 18.5622 - val_loss: 20.2077 - val_mse: 20.2077\n",
      "Epoch 26/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 18.6393 - mse: 18.6393 - val_loss: 20.4881 - val_mse: 20.4881\n",
      "Epoch 27/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 18.5373 - mse: 18.5373 - val_loss: 20.3662 - val_mse: 20.3662\n",
      "Epoch 28/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.5216 - mse: 18.5216 - val_loss: 20.1999 - val_mse: 20.1999\n",
      "Epoch 29/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 18.5502 - mse: 18.5502 - val_loss: 20.9979 - val_mse: 20.9979\n",
      "Epoch 30/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 18.4521 - mse: 18.4521 - val_loss: 20.4188 - val_mse: 20.4188\n",
      "Epoch 31/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.4735 - mse: 18.4735 - val_loss: 20.2732 - val_mse: 20.2732\n",
      "Epoch 32/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 18.4809 - mse: 18.4809 - val_loss: 20.2164 - val_mse: 20.2164\n",
      "Epoch 33/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.4765 - mse: 18.4765 - val_loss: 20.2857 - val_mse: 20.2857\n",
      "Epoch 34/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.4825 - mse: 18.4825 - val_loss: 20.6066 - val_mse: 20.6066\n",
      "Epoch 35/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 18.4022 - mse: 18.4022 - val_loss: 20.1569 - val_mse: 20.1569\n",
      "Epoch 36/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 18.5667 - mse: 18.5667 - val_loss: 20.3911 - val_mse: 20.3911\n",
      "Epoch 37/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 18.4710 - mse: 18.4710 - val_loss: 20.4927 - val_mse: 20.4927\n",
      "Epoch 38/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 18.4049 - mse: 18.4049 - val_loss: 20.2800 - val_mse: 20.2800\n",
      "Epoch 39/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 18.4109 - mse: 18.4109 - val_loss: 20.3375 - val_mse: 20.3375\n",
      "Epoch 40/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.4264 - mse: 18.4264 - val_loss: 19.9819 - val_mse: 19.9819\n",
      "Epoch 41/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.4699 - mse: 18.4699 - val_loss: 20.2036 - val_mse: 20.2036\n",
      "Epoch 42/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.4108 - mse: 18.4108 - val_loss: 20.4095 - val_mse: 20.4095\n",
      "Epoch 43/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.3743 - mse: 18.3743 - val_loss: 20.3756 - val_mse: 20.3756\n",
      "Epoch 44/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.3555 - mse: 18.3555 - val_loss: 20.2406 - val_mse: 20.2406\n",
      "Epoch 45/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.3575 - mse: 18.3575 - val_loss: 20.2222 - val_mse: 20.2222\n",
      "Epoch 46/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.3576 - mse: 18.3576 - val_loss: 21.0224 - val_mse: 21.0224\n",
      "Epoch 47/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.2765 - mse: 18.2765 - val_loss: 20.1613 - val_mse: 20.1613\n",
      "Epoch 48/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.3362 - mse: 18.3362 - val_loss: 20.2946 - val_mse: 20.2946\n",
      "Epoch 49/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.3126 - mse: 18.3126 - val_loss: 20.0223 - val_mse: 20.0223\n",
      "Epoch 50/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.3086 - mse: 18.3086 - val_loss: 20.5118 - val_mse: 20.5118\n",
      "Epoch 51/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.2098 - mse: 18.2098 - val_loss: 19.8355 - val_mse: 19.8355\n",
      "Epoch 52/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.3417 - mse: 18.3417 - val_loss: 20.3308 - val_mse: 20.3308\n",
      "Epoch 53/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.2622 - mse: 18.2622 - val_loss: 19.9577 - val_mse: 19.9577\n",
      "Epoch 54/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.2976 - mse: 18.2976 - val_loss: 20.3452 - val_mse: 20.3452\n",
      "Epoch 55/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 18.1964 - mse: 18.1964 - val_loss: 19.8363 - val_mse: 19.8363\n",
      "Epoch 56/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.3307 - mse: 18.3307 - val_loss: 19.8275 - val_mse: 19.8275\n",
      "Epoch 57/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.3038 - mse: 18.3038 - val_loss: 20.5524 - val_mse: 20.5524\n",
      "Epoch 58/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.2174 - mse: 18.2174 - val_loss: 20.1421 - val_mse: 20.1421\n",
      "Epoch 59/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.2245 - mse: 18.2245 - val_loss: 20.0183 - val_mse: 20.0183\n",
      "Epoch 60/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.2581 - mse: 18.2581 - val_loss: 20.0857 - val_mse: 20.0857\n",
      "Epoch 61/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.2867 - mse: 18.2867 - val_loss: 20.4462 - val_mse: 20.4462\n",
      "Epoch 62/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.2160 - mse: 18.2160 - val_loss: 20.5174 - val_mse: 20.5174\n",
      "Epoch 63/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.2357 - mse: 18.2357 - val_loss: 19.8273 - val_mse: 19.8273\n",
      "Epoch 64/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.2849 - mse: 18.2849 - val_loss: 19.6149 - val_mse: 19.6149\n",
      "Epoch 65/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.2596 - mse: 18.2596 - val_loss: 20.1065 - val_mse: 20.1065\n",
      "Epoch 66/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.2427 - mse: 18.2427 - val_loss: 20.1672 - val_mse: 20.1672\n",
      "Epoch 67/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.2023 - mse: 18.2023 - val_loss: 20.0539 - val_mse: 20.0539\n",
      "Epoch 68/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.2424 - mse: 18.2424 - val_loss: 20.0177 - val_mse: 20.0177\n",
      "Epoch 69/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.1443 - mse: 18.1443 - val_loss: 19.7706 - val_mse: 19.7706\n",
      "Epoch 70/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.2120 - mse: 18.2120 - val_loss: 19.8315 - val_mse: 19.8315\n",
      "Epoch 71/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.2226 - mse: 18.2226 - val_loss: 20.0554 - val_mse: 20.0554\n",
      "Epoch 72/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 18.1993 - mse: 18.1993 - val_loss: 19.7966 - val_mse: 19.7966\n",
      "Epoch 73/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.1789 - mse: 18.1789 - val_loss: 19.6737 - val_mse: 19.6737\n",
      "Epoch 74/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 18.1808 - mse: 18.1808 - val_loss: 19.9279 - val_mse: 19.9279\n",
      "Epoch 75/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.2200 - mse: 18.2200 - val_loss: 20.6808 - val_mse: 20.6808\n",
      "Epoch 76/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.1120 - mse: 18.1120 - val_loss: 19.8505 - val_mse: 19.8505\n",
      "Epoch 77/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.1663 - mse: 18.1663 - val_loss: 19.7801 - val_mse: 19.7801\n",
      "Epoch 78/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.2182 - mse: 18.2182 - val_loss: 19.6657 - val_mse: 19.6657\n",
      "Epoch 79/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.1297 - mse: 18.1297 - val_loss: 19.8535 - val_mse: 19.8535\n",
      "Epoch 80/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.1470 - mse: 18.1470 - val_loss: 20.1240 - val_mse: 20.1240\n",
      "Epoch 81/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.1239 - mse: 18.1239 - val_loss: 20.1563 - val_mse: 20.1563\n",
      "Epoch 82/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.0450 - mse: 18.0450 - val_loss: 19.5329 - val_mse: 19.5329\n",
      "Epoch 83/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.1760 - mse: 18.1760 - val_loss: 19.7079 - val_mse: 19.7079\n",
      "Epoch 84/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.1401 - mse: 18.1401 - val_loss: 19.8219 - val_mse: 19.8219\n",
      "Epoch 85/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 18.1454 - mse: 18.1454 - val_loss: 20.4974 - val_mse: 20.4974\n",
      "Epoch 86/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.0833 - mse: 18.0833 - val_loss: 20.1098 - val_mse: 20.1098\n",
      "Epoch 87/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 18.1087 - mse: 18.1087 - val_loss: 20.0727 - val_mse: 20.0727\n",
      "Epoch 88/500\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 18.0810 - mse: 18.0810 - val_loss: 19.6424 - val_mse: 19.6424\n",
      "Epoch 89/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 18.0623 - mse: 18.0623 - val_loss: 19.5229 - val_mse: 19.5229\n",
      "Epoch 90/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 18.2105 - mse: 18.2105 - val_loss: 19.7147 - val_mse: 19.7147\n",
      "Epoch 91/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 18.1224 - mse: 18.1224 - val_loss: 20.1553 - val_mse: 20.1553\n",
      "Epoch 92/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.9832 - mse: 17.9832 - val_loss: 19.5380 - val_mse: 19.5380\n",
      "Epoch 93/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.1059 - mse: 18.1059 - val_loss: 19.5761 - val_mse: 19.5761\n",
      "Epoch 94/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 18.1070 - mse: 18.1070 - val_loss: 19.6387 - val_mse: 19.6387\n",
      "Epoch 95/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.0298 - mse: 18.0298 - val_loss: 19.9442 - val_mse: 19.9442\n",
      "Epoch 96/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.0888 - mse: 18.0888 - val_loss: 19.6358 - val_mse: 19.6358\n",
      "Epoch 97/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.0608 - mse: 18.0608 - val_loss: 19.7862 - val_mse: 19.7862\n",
      "Epoch 98/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 18.0048 - mse: 18.0048 - val_loss: 19.4241 - val_mse: 19.4241\n",
      "Epoch 99/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.0681 - mse: 18.0681 - val_loss: 19.9053 - val_mse: 19.9053\n",
      "Epoch 100/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.0080 - mse: 18.0080 - val_loss: 19.6786 - val_mse: 19.6786\n",
      "Epoch 101/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 18.0068 - mse: 18.0068 - val_loss: 19.6385 - val_mse: 19.6385\n",
      "Epoch 102/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 18.0660 - mse: 18.0660 - val_loss: 20.2896 - val_mse: 20.2896\n",
      "Epoch 103/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.9862 - mse: 17.9862 - val_loss: 19.4004 - val_mse: 19.4004\n",
      "Epoch 104/500\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 18.0979 - mse: 18.0979 - val_loss: 19.7496 - val_mse: 19.7496\n",
      "Epoch 105/500\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 18.0079 - mse: 18.0079 - val_loss: 19.7387 - val_mse: 19.7387\n",
      "Epoch 106/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 18.0238 - mse: 18.0238 - val_loss: 19.7842 - val_mse: 19.7842\n",
      "Epoch 107/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.0222 - mse: 18.0222 - val_loss: 20.0140 - val_mse: 20.0140\n",
      "Epoch 108/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.0133 - mse: 18.0133 - val_loss: 19.9084 - val_mse: 19.9084\n",
      "Epoch 109/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.9925 - mse: 17.9925 - val_loss: 19.4333 - val_mse: 19.4333\n",
      "Epoch 110/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.0368 - mse: 18.0368 - val_loss: 19.5656 - val_mse: 19.5656\n",
      "Epoch 111/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.0141 - mse: 18.0141 - val_loss: 19.5054 - val_mse: 19.5054\n",
      "Epoch 112/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.0297 - mse: 18.0297 - val_loss: 19.4294 - val_mse: 19.4294\n",
      "Epoch 113/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.9943 - mse: 17.9943 - val_loss: 19.2701 - val_mse: 19.2701\n",
      "Epoch 114/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.0398 - mse: 18.0398 - val_loss: 19.8753 - val_mse: 19.8753\n",
      "Epoch 115/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.9651 - mse: 17.9651 - val_loss: 19.4708 - val_mse: 19.4708\n",
      "Epoch 116/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.0427 - mse: 18.0427 - val_loss: 19.7900 - val_mse: 19.7900\n",
      "Epoch 117/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.9523 - mse: 17.9523 - val_loss: 19.5191 - val_mse: 19.5191\n",
      "Epoch 118/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.0097 - mse: 18.0097 - val_loss: 19.9542 - val_mse: 19.9542\n",
      "Epoch 119/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.9352 - mse: 17.9352 - val_loss: 19.4039 - val_mse: 19.4039\n",
      "Epoch 120/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.0250 - mse: 18.0250 - val_loss: 19.8481 - val_mse: 19.8481\n",
      "Epoch 121/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 1s 9ms/step - loss: 17.9420 - mse: 17.9420 - val_loss: 19.5438 - val_mse: 19.5438\n",
      "Epoch 122/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.0564 - mse: 18.0564 - val_loss: 19.4649 - val_mse: 19.4649\n",
      "Epoch 123/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.0001 - mse: 18.0001 - val_loss: 19.5695 - val_mse: 19.5695\n",
      "Epoch 124/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.9809 - mse: 17.9809 - val_loss: 19.5054 - val_mse: 19.5054\n",
      "Epoch 125/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.9751 - mse: 17.9751 - val_loss: 19.5387 - val_mse: 19.5387\n",
      "Epoch 126/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.9538 - mse: 17.9538 - val_loss: 19.4139 - val_mse: 19.4139\n",
      "Epoch 127/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.9670 - mse: 17.9670 - val_loss: 19.2891 - val_mse: 19.2891\n",
      "Epoch 128/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.9480 - mse: 17.9480 - val_loss: 19.2042 - val_mse: 19.2042\n",
      "Epoch 129/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.9633 - mse: 17.9633 - val_loss: 19.3263 - val_mse: 19.3263\n",
      "Epoch 130/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.9128 - mse: 17.9128 - val_loss: 19.1457 - val_mse: 19.1457\n",
      "Epoch 131/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.0210 - mse: 18.0210 - val_loss: 19.7123 - val_mse: 19.7123\n",
      "Epoch 132/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.9132 - mse: 17.9132 - val_loss: 19.1104 - val_mse: 19.1104\n",
      "Epoch 133/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 18.0527 - mse: 18.0527 - val_loss: 19.4329 - val_mse: 19.4329\n",
      "Epoch 134/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.9508 - mse: 17.9508 - val_loss: 19.1730 - val_mse: 19.1730\n",
      "Epoch 135/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.9661 - mse: 17.9661 - val_loss: 19.3165 - val_mse: 19.3165\n",
      "Epoch 136/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.9589 - mse: 17.9589 - val_loss: 19.3723 - val_mse: 19.3723\n",
      "Epoch 137/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.9876 - mse: 17.9876 - val_loss: 19.5717 - val_mse: 19.5717\n",
      "Epoch 138/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.9186 - mse: 17.9186 - val_loss: 19.3540 - val_mse: 19.3540\n",
      "Epoch 139/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.9826 - mse: 17.9826 - val_loss: 19.5881 - val_mse: 19.5881\n",
      "Epoch 140/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.9401 - mse: 17.9401 - val_loss: 19.7527 - val_mse: 19.7527\n",
      "Epoch 141/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.9423 - mse: 17.9423 - val_loss: 20.2302 - val_mse: 20.2302\n",
      "Epoch 142/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.9177 - mse: 17.9177 - val_loss: 19.8384 - val_mse: 19.8384\n",
      "Epoch 143/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8901 - mse: 17.8901 - val_loss: 19.3918 - val_mse: 19.3918\n",
      "Epoch 144/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8819 - mse: 17.8819 - val_loss: 19.4024 - val_mse: 19.4024\n",
      "Epoch 145/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.9318 - mse: 17.9318 - val_loss: 19.6216 - val_mse: 19.6216\n",
      "Epoch 146/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.9065 - mse: 17.9065 - val_loss: 19.3712 - val_mse: 19.3712\n",
      "Epoch 147/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.9474 - mse: 17.9474 - val_loss: 19.3124 - val_mse: 19.3124\n",
      "Epoch 148/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.9009 - mse: 17.9009 - val_loss: 19.3220 - val_mse: 19.3220\n",
      "Epoch 149/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8143 - mse: 17.8143 - val_loss: 19.0651 - val_mse: 19.0651\n",
      "Epoch 150/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.9664 - mse: 17.9664 - val_loss: 19.3271 - val_mse: 19.3271\n",
      "Epoch 151/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.9177 - mse: 17.9177 - val_loss: 19.7423 - val_mse: 19.7423\n",
      "Epoch 152/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.9324 - mse: 17.9324 - val_loss: 19.6195 - val_mse: 19.6195\n",
      "Epoch 153/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.8676 - mse: 17.8676 - val_loss: 19.5969 - val_mse: 19.5969\n",
      "Epoch 154/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.9225 - mse: 17.9225 - val_loss: 19.8097 - val_mse: 19.8097\n",
      "Epoch 155/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8340 - mse: 17.8340 - val_loss: 19.2474 - val_mse: 19.2474\n",
      "Epoch 156/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.9738 - mse: 17.9738 - val_loss: 19.9797 - val_mse: 19.9797\n",
      "Epoch 157/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8698 - mse: 17.8698 - val_loss: 19.6698 - val_mse: 19.6698\n",
      "Epoch 158/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.8010 - mse: 17.8010 - val_loss: 19.1919 - val_mse: 19.1919\n",
      "Epoch 159/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.9741 - mse: 17.9741 - val_loss: 20.0316 - val_mse: 20.0316\n",
      "Epoch 160/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.8340 - mse: 17.8340 - val_loss: 19.4659 - val_mse: 19.4659\n",
      "Epoch 161/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.8861 - mse: 17.8861 - val_loss: 19.1135 - val_mse: 19.1135\n",
      "Epoch 162/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.9365 - mse: 17.9365 - val_loss: 19.3381 - val_mse: 19.3381\n",
      "Epoch 163/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8511 - mse: 17.8511 - val_loss: 19.2198 - val_mse: 19.2198\n",
      "Epoch 164/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8981 - mse: 17.8981 - val_loss: 19.2905 - val_mse: 19.2905\n",
      "Epoch 165/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8461 - mse: 17.8461 - val_loss: 19.0463 - val_mse: 19.0463\n",
      "Epoch 166/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.8999 - mse: 17.8999 - val_loss: 19.6679 - val_mse: 19.6679\n",
      "Epoch 167/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.8475 - mse: 17.8475 - val_loss: 19.4783 - val_mse: 19.4783\n",
      "Epoch 168/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.8209 - mse: 17.8209 - val_loss: 19.4071 - val_mse: 19.4071\n",
      "Epoch 169/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8794 - mse: 17.8794 - val_loss: 19.4767 - val_mse: 19.4767\n",
      "Epoch 170/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8541 - mse: 17.8541 - val_loss: 19.2975 - val_mse: 19.2975\n",
      "Epoch 171/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.8345 - mse: 17.8345 - val_loss: 19.3145 - val_mse: 19.3145\n",
      "Epoch 172/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8623 - mse: 17.8623 - val_loss: 19.2636 - val_mse: 19.2636\n",
      "Epoch 173/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.8698 - mse: 17.8698 - val_loss: 19.6696 - val_mse: 19.6696\n",
      "Epoch 174/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.7931 - mse: 17.7931 - val_loss: 19.2232 - val_mse: 19.2232\n",
      "Epoch 175/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8721 - mse: 17.8721 - val_loss: 19.5703 - val_mse: 19.5703\n",
      "Epoch 176/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.8274 - mse: 17.8274 - val_loss: 19.3447 - val_mse: 19.3447\n",
      "Epoch 177/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8208 - mse: 17.8208 - val_loss: 19.2541 - val_mse: 19.2541\n",
      "Epoch 178/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8536 - mse: 17.8536 - val_loss: 19.3839 - val_mse: 19.3839\n",
      "Epoch 179/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8012 - mse: 17.8012 - val_loss: 19.1902 - val_mse: 19.1902\n",
      "Epoch 180/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.7968 - mse: 17.7968 - val_loss: 19.4254 - val_mse: 19.4254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7831 - mse: 17.7831 - val_loss: 19.1385 - val_mse: 19.1385\n",
      "Epoch 182/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8462 - mse: 17.8462 - val_loss: 19.5400 - val_mse: 19.5400\n",
      "Epoch 183/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7943 - mse: 17.7943 - val_loss: 19.1368 - val_mse: 19.1368\n",
      "Epoch 184/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8343 - mse: 17.8343 - val_loss: 19.3912 - val_mse: 19.3912\n",
      "Epoch 185/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7941 - mse: 17.7941 - val_loss: 19.2310 - val_mse: 19.2310\n",
      "Epoch 186/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8262 - mse: 17.8262 - val_loss: 19.1375 - val_mse: 19.1375\n",
      "Epoch 187/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8482 - mse: 17.8482 - val_loss: 19.2742 - val_mse: 19.2742\n",
      "Epoch 188/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7761 - mse: 17.7761 - val_loss: 19.1802 - val_mse: 19.1802\n",
      "Epoch 189/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8187 - mse: 17.8187 - val_loss: 19.1993 - val_mse: 19.1993\n",
      "Epoch 190/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8371 - mse: 17.8371 - val_loss: 19.5794 - val_mse: 19.5794\n",
      "Epoch 191/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7954 - mse: 17.7954 - val_loss: 19.5805 - val_mse: 19.5805\n",
      "Epoch 192/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7698 - mse: 17.7698 - val_loss: 19.4601 - val_mse: 19.4601\n",
      "Epoch 193/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8545 - mse: 17.8545 - val_loss: 19.8363 - val_mse: 19.8363\n",
      "Epoch 194/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7948 - mse: 17.7948 - val_loss: 19.5110 - val_mse: 19.5110\n",
      "Epoch 195/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7950 - mse: 17.7950 - val_loss: 19.8113 - val_mse: 19.8113\n",
      "Epoch 196/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7649 - mse: 17.7649 - val_loss: 19.0530 - val_mse: 19.0530\n",
      "Epoch 197/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8228 - mse: 17.8228 - val_loss: 19.2242 - val_mse: 19.2242\n",
      "Epoch 198/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7805 - mse: 17.7805 - val_loss: 18.9533 - val_mse: 18.9533\n",
      "Epoch 199/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.9566 - mse: 17.9566 - val_loss: 18.9179 - val_mse: 18.9179\n",
      "Epoch 200/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8039 - mse: 17.8039 - val_loss: 19.4393 - val_mse: 19.4393\n",
      "Epoch 201/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8028 - mse: 17.8028 - val_loss: 19.2970 - val_mse: 19.2970\n",
      "Epoch 202/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8257 - mse: 17.8257 - val_loss: 19.7789 - val_mse: 19.7789\n",
      "Epoch 203/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7782 - mse: 17.7782 - val_loss: 19.3310 - val_mse: 19.3310\n",
      "Epoch 204/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.7541 - mse: 17.7541 - val_loss: 19.0941 - val_mse: 19.0941\n",
      "Epoch 205/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.7630 - mse: 17.7630 - val_loss: 18.9453 - val_mse: 18.9453\n",
      "Epoch 206/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.9265 - mse: 17.9265 - val_loss: 18.9591 - val_mse: 18.9591\n",
      "Epoch 207/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7773 - mse: 17.7773 - val_loss: 18.9851 - val_mse: 18.9851\n",
      "Epoch 208/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7302 - mse: 17.7302 - val_loss: 18.9972 - val_mse: 18.9972\n",
      "Epoch 209/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.7361 - mse: 17.7361 - val_loss: 18.9437 - val_mse: 18.9437\n",
      "Epoch 210/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8294 - mse: 17.8294 - val_loss: 19.3191 - val_mse: 19.3191\n",
      "Epoch 211/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7928 - mse: 17.7928 - val_loss: 19.0976 - val_mse: 19.0976\n",
      "Epoch 212/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7997 - mse: 17.7997 - val_loss: 19.0041 - val_mse: 19.0041\n",
      "Epoch 213/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7763 - mse: 17.7763 - val_loss: 19.0603 - val_mse: 19.0603\n",
      "Epoch 214/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8108 - mse: 17.8108 - val_loss: 19.2024 - val_mse: 19.2024\n",
      "Epoch 215/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.7238 - mse: 17.7238 - val_loss: 19.0041 - val_mse: 19.0041\n",
      "Epoch 216/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.7740 - mse: 17.7740 - val_loss: 18.8688 - val_mse: 18.8688\n",
      "Epoch 217/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8260 - mse: 17.8260 - val_loss: 19.5538 - val_mse: 19.5538\n",
      "Epoch 218/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7377 - mse: 17.7377 - val_loss: 19.2305 - val_mse: 19.2305\n",
      "Epoch 219/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8056 - mse: 17.8056 - val_loss: 19.2205 - val_mse: 19.2205\n",
      "Epoch 220/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8003 - mse: 17.8003 - val_loss: 19.8461 - val_mse: 19.8461\n",
      "Epoch 221/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6994 - mse: 17.6994 - val_loss: 19.1313 - val_mse: 19.1313\n",
      "Epoch 222/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7362 - mse: 17.7362 - val_loss: 19.1044 - val_mse: 19.1044\n",
      "Epoch 223/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.7306 - mse: 17.7306 - val_loss: 19.1078 - val_mse: 19.1078\n",
      "Epoch 224/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.7606 - mse: 17.7606 - val_loss: 19.2328 - val_mse: 19.2328\n",
      "Epoch 225/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8003 - mse: 17.8003 - val_loss: 19.2188 - val_mse: 19.2188\n",
      "Epoch 226/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6822 - mse: 17.6822 - val_loss: 19.0367 - val_mse: 19.0367\n",
      "Epoch 227/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6113 - mse: 17.6113 - val_loss: 18.7168 - val_mse: 18.7168\n",
      "Epoch 228/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8329 - mse: 17.8329 - val_loss: 18.9579 - val_mse: 18.9579\n",
      "Epoch 229/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7581 - mse: 17.7581 - val_loss: 19.9654 - val_mse: 19.9654\n",
      "Epoch 230/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6629 - mse: 17.6629 - val_loss: 19.3874 - val_mse: 19.3874\n",
      "Epoch 231/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7711 - mse: 17.7711 - val_loss: 19.3539 - val_mse: 19.3539\n",
      "Epoch 232/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.6730 - mse: 17.6730 - val_loss: 19.1866 - val_mse: 19.1866\n",
      "Epoch 233/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.7544 - mse: 17.7544 - val_loss: 19.4556 - val_mse: 19.4556\n",
      "Epoch 234/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7228 - mse: 17.7228 - val_loss: 19.1357 - val_mse: 19.1357\n",
      "Epoch 235/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7175 - mse: 17.7175 - val_loss: 18.9332 - val_mse: 18.9332\n",
      "Epoch 236/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7366 - mse: 17.7366 - val_loss: 19.0054 - val_mse: 19.0054\n",
      "Epoch 237/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.8113 - mse: 17.8113 - val_loss: 19.2317 - val_mse: 19.2317\n",
      "Epoch 238/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7250 - mse: 17.7250 - val_loss: 19.2535 - val_mse: 19.2535\n",
      "Epoch 239/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6627 - mse: 17.6627 - val_loss: 18.8110 - val_mse: 18.8110\n",
      "Epoch 240/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7015 - mse: 17.7015 - val_loss: 19.0358 - val_mse: 19.0358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7162 - mse: 17.7162 - val_loss: 18.9716 - val_mse: 18.9716\n",
      "Epoch 242/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7231 - mse: 17.7231 - val_loss: 19.0160 - val_mse: 19.0160\n",
      "Epoch 243/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6536 - mse: 17.6536 - val_loss: 18.8074 - val_mse: 18.8074\n",
      "Epoch 244/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7256 - mse: 17.7256 - val_loss: 19.3641 - val_mse: 19.3641\n",
      "Epoch 245/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7294 - mse: 17.7294 - val_loss: 19.1746 - val_mse: 19.1746\n",
      "Epoch 246/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.6546 - mse: 17.6546 - val_loss: 18.7129 - val_mse: 18.7129\n",
      "Epoch 247/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.7130 - mse: 17.7130 - val_loss: 19.3178 - val_mse: 19.3178\n",
      "Epoch 248/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.6636 - mse: 17.6636 - val_loss: 19.1628 - val_mse: 19.1628\n",
      "Epoch 249/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.6570 - mse: 17.6570 - val_loss: 18.9957 - val_mse: 18.9957\n",
      "Epoch 250/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7061 - mse: 17.7061 - val_loss: 19.4598 - val_mse: 19.4598\n",
      "Epoch 251/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6114 - mse: 17.6114 - val_loss: 18.9526 - val_mse: 18.9526\n",
      "Epoch 252/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6682 - mse: 17.6682 - val_loss: 18.8351 - val_mse: 18.8351\n",
      "Epoch 253/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7591 - mse: 17.7591 - val_loss: 19.2260 - val_mse: 19.2260\n",
      "Epoch 254/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6646 - mse: 17.6646 - val_loss: 19.5726 - val_mse: 19.5726\n",
      "Epoch 255/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.6802 - mse: 17.6802 - val_loss: 19.1866 - val_mse: 19.1866\n",
      "Epoch 256/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6584 - mse: 17.6584 - val_loss: 18.9841 - val_mse: 18.9841\n",
      "Epoch 257/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7341 - mse: 17.7341 - val_loss: 18.8798 - val_mse: 18.8798\n",
      "Epoch 258/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7105 - mse: 17.7105 - val_loss: 19.0521 - val_mse: 19.0521\n",
      "Epoch 259/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6563 - mse: 17.6563 - val_loss: 18.9179 - val_mse: 18.9179\n",
      "Epoch 260/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6892 - mse: 17.6892 - val_loss: 18.8997 - val_mse: 18.8997\n",
      "Epoch 261/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7317 - mse: 17.7317 - val_loss: 19.6346 - val_mse: 19.6346\n",
      "Epoch 262/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6495 - mse: 17.6495 - val_loss: 19.2722 - val_mse: 19.2722\n",
      "Epoch 263/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.5850 - mse: 17.5850 - val_loss: 18.8872 - val_mse: 18.8872\n",
      "Epoch 264/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7095 - mse: 17.7095 - val_loss: 19.4632 - val_mse: 19.4632\n",
      "Epoch 265/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6001 - mse: 17.6001 - val_loss: 18.9478 - val_mse: 18.9478\n",
      "Epoch 266/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6853 - mse: 17.6853 - val_loss: 19.4940 - val_mse: 19.4940\n",
      "Epoch 267/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6186 - mse: 17.6186 - val_loss: 19.1512 - val_mse: 19.1512\n",
      "Epoch 268/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6760 - mse: 17.6760 - val_loss: 18.7999 - val_mse: 18.7999\n",
      "Epoch 269/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6655 - mse: 17.6655 - val_loss: 19.3345 - val_mse: 19.3345\n",
      "Epoch 270/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6495 - mse: 17.6495 - val_loss: 19.5361 - val_mse: 19.5361\n",
      "Epoch 271/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6283 - mse: 17.6283 - val_loss: 19.2344 - val_mse: 19.2344\n",
      "Epoch 272/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6352 - mse: 17.6352 - val_loss: 19.5434 - val_mse: 19.5434\n",
      "Epoch 273/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.6237 - mse: 17.6237 - val_loss: 18.9536 - val_mse: 18.9536\n",
      "Epoch 274/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6000 - mse: 17.6000 - val_loss: 18.6716 - val_mse: 18.6716\n",
      "Epoch 275/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6639 - mse: 17.6639 - val_loss: 18.6331 - val_mse: 18.6331\n",
      "Epoch 276/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6853 - mse: 17.6853 - val_loss: 19.2207 - val_mse: 19.2207\n",
      "Epoch 277/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6273 - mse: 17.6273 - val_loss: 19.2855 - val_mse: 19.2855\n",
      "Epoch 278/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6677 - mse: 17.6677 - val_loss: 19.7617 - val_mse: 19.7617\n",
      "Epoch 279/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.5807 - mse: 17.5807 - val_loss: 19.1919 - val_mse: 19.1919\n",
      "Epoch 280/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.5729 - mse: 17.5729 - val_loss: 18.8868 - val_mse: 18.8868\n",
      "Epoch 281/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6320 - mse: 17.6320 - val_loss: 19.1745 - val_mse: 19.1745\n",
      "Epoch 282/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6139 - mse: 17.6139 - val_loss: 19.0067 - val_mse: 19.0067\n",
      "Epoch 283/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.5796 - mse: 17.5796 - val_loss: 19.4563 - val_mse: 19.4563\n",
      "Epoch 284/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.5204 - mse: 17.5204 - val_loss: 18.6151 - val_mse: 18.6151\n",
      "Epoch 285/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7579 - mse: 17.7579 - val_loss: 19.1766 - val_mse: 19.1766\n",
      "Epoch 286/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.5629 - mse: 17.5629 - val_loss: 18.9555 - val_mse: 18.9555\n",
      "Epoch 287/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.5645 - mse: 17.5645 - val_loss: 18.9474 - val_mse: 18.9474\n",
      "Epoch 288/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.5972 - mse: 17.5972 - val_loss: 18.7398 - val_mse: 18.7398\n",
      "Epoch 289/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.5970 - mse: 17.5970 - val_loss: 19.0472 - val_mse: 19.0472\n",
      "Epoch 290/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.6049 - mse: 17.6049 - val_loss: 19.2061 - val_mse: 19.2061\n",
      "Epoch 291/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.5469 - mse: 17.5469 - val_loss: 18.9541 - val_mse: 18.9541\n",
      "Epoch 292/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.6459 - mse: 17.6459 - val_loss: 20.0707 - val_mse: 20.0707\n",
      "Epoch 293/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.5683 - mse: 17.5683 - val_loss: 19.5834 - val_mse: 19.5834\n",
      "Epoch 294/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.5768 - mse: 17.5768 - val_loss: 19.2786 - val_mse: 19.2786\n",
      "Epoch 295/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.5761 - mse: 17.5761 - val_loss: 19.3870 - val_mse: 19.3870\n",
      "Epoch 296/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6060 - mse: 17.6060 - val_loss: 18.7929 - val_mse: 18.7929\n",
      "Epoch 297/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6281 - mse: 17.6281 - val_loss: 18.9693 - val_mse: 18.9693\n",
      "Epoch 298/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.5712 - mse: 17.5712 - val_loss: 19.0794 - val_mse: 19.0794\n",
      "Epoch 299/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.6026 - mse: 17.6026 - val_loss: 19.2652 - val_mse: 19.2652\n",
      "Epoch 300/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.5044 - mse: 17.5044 - val_loss: 18.9316 - val_mse: 18.9316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.5462 - mse: 17.5462 - val_loss: 19.1605 - val_mse: 19.1605\n",
      "Epoch 302/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.5297 - mse: 17.5297 - val_loss: 18.8589 - val_mse: 18.8589\n",
      "Epoch 303/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.5594 - mse: 17.5594 - val_loss: 18.9578 - val_mse: 18.9578\n",
      "Epoch 304/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.6408 - mse: 17.6408 - val_loss: 19.3887 - val_mse: 19.3887\n",
      "Epoch 305/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.5000 - mse: 17.5000 - val_loss: 19.1978 - val_mse: 19.1978\n",
      "Epoch 306/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.5224 - mse: 17.5224 - val_loss: 18.9089 - val_mse: 18.9089\n",
      "Epoch 307/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6092 - mse: 17.6092 - val_loss: 19.3842 - val_mse: 19.3842\n",
      "Epoch 308/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.7220 - mse: 17.7220 - val_loss: 18.7862 - val_mse: 18.7862\n",
      "Epoch 309/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.5612 - mse: 17.5612 - val_loss: 18.7373 - val_mse: 18.7373\n",
      "Epoch 310/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.5691 - mse: 17.5691 - val_loss: 18.8009 - val_mse: 18.8009\n",
      "Epoch 311/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.5956 - mse: 17.5956 - val_loss: 19.2016 - val_mse: 19.2016\n",
      "Epoch 312/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.5366 - mse: 17.5366 - val_loss: 18.9324 - val_mse: 18.9324\n",
      "Epoch 313/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.4954 - mse: 17.4954 - val_loss: 18.6021 - val_mse: 18.6021\n",
      "Epoch 314/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6308 - mse: 17.6308 - val_loss: 19.2501 - val_mse: 19.2501\n",
      "Epoch 315/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.5489 - mse: 17.5489 - val_loss: 19.0897 - val_mse: 19.0897\n",
      "Epoch 316/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.5043 - mse: 17.5043 - val_loss: 18.9166 - val_mse: 18.9166\n",
      "Epoch 317/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.5815 - mse: 17.5815 - val_loss: 19.0626 - val_mse: 19.0626\n",
      "Epoch 318/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.4992 - mse: 17.4992 - val_loss: 18.8950 - val_mse: 18.8950\n",
      "Epoch 319/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.5649 - mse: 17.5649 - val_loss: 18.6785 - val_mse: 18.6785\n",
      "Epoch 320/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.5798 - mse: 17.5798 - val_loss: 19.1749 - val_mse: 19.1749\n",
      "Epoch 321/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.5165 - mse: 17.5165 - val_loss: 19.2857 - val_mse: 19.2857\n",
      "Epoch 322/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.4684 - mse: 17.4684 - val_loss: 18.8868 - val_mse: 18.8868\n",
      "Epoch 323/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.5156 - mse: 17.5156 - val_loss: 19.2174 - val_mse: 19.2174\n",
      "Epoch 324/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.4856 - mse: 17.4856 - val_loss: 18.9528 - val_mse: 18.9528\n",
      "Epoch 325/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.5414 - mse: 17.5414 - val_loss: 19.0743 - val_mse: 19.0743\n",
      "Epoch 326/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.5065 - mse: 17.5065 - val_loss: 18.9473 - val_mse: 18.9473\n",
      "Epoch 327/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.4970 - mse: 17.4970 - val_loss: 18.8600 - val_mse: 18.8600\n",
      "Epoch 328/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.4464 - mse: 17.4464 - val_loss: 18.7095 - val_mse: 18.7095\n",
      "Epoch 329/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.5177 - mse: 17.5177 - val_loss: 19.1744 - val_mse: 19.1744\n",
      "Epoch 330/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.4956 - mse: 17.4956 - val_loss: 18.9249 - val_mse: 18.9249\n",
      "Epoch 331/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.4069 - mse: 17.4069 - val_loss: 18.5342 - val_mse: 18.5342\n",
      "Epoch 332/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.6846 - mse: 17.6846 - val_loss: 19.4052 - val_mse: 19.4052\n",
      "Epoch 333/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.4743 - mse: 17.4743 - val_loss: 19.4801 - val_mse: 19.4801\n",
      "Epoch 334/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.5052 - mse: 17.5052 - val_loss: 18.9237 - val_mse: 18.9237\n",
      "Epoch 335/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.4899 - mse: 17.4899 - val_loss: 18.6658 - val_mse: 18.6658\n",
      "Epoch 336/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.5104 - mse: 17.5104 - val_loss: 18.9430 - val_mse: 18.9430\n",
      "Epoch 337/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.4691 - mse: 17.4691 - val_loss: 18.9472 - val_mse: 18.9472\n",
      "Epoch 338/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.4423 - mse: 17.4423 - val_loss: 18.7615 - val_mse: 18.7615\n",
      "Epoch 339/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.5755 - mse: 17.5755 - val_loss: 19.5018 - val_mse: 19.5018\n",
      "Epoch 340/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.4351 - mse: 17.4351 - val_loss: 18.8389 - val_mse: 18.8389\n",
      "Epoch 341/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.7258 - mse: 17.7258 - val_loss: 19.4541 - val_mse: 19.4541\n",
      "Epoch 342/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.4823 - mse: 17.4823 - val_loss: 19.2856 - val_mse: 19.2856\n",
      "Epoch 343/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.4183 - mse: 17.4183 - val_loss: 18.5492 - val_mse: 18.5492\n",
      "Epoch 344/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.4830 - mse: 17.4830 - val_loss: 19.0178 - val_mse: 19.0178\n",
      "Epoch 345/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.4361 - mse: 17.4361 - val_loss: 18.9047 - val_mse: 18.9047\n",
      "Epoch 346/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.5808 - mse: 17.5808 - val_loss: 19.2262 - val_mse: 19.2262\n",
      "Epoch 347/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.4368 - mse: 17.4368 - val_loss: 18.7970 - val_mse: 18.7970\n",
      "Epoch 348/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.4253 - mse: 17.4253 - val_loss: 18.8160 - val_mse: 18.8160\n",
      "Epoch 349/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.4818 - mse: 17.4818 - val_loss: 19.6179 - val_mse: 19.6179\n",
      "Epoch 350/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.4130 - mse: 17.4130 - val_loss: 19.0739 - val_mse: 19.0739\n",
      "Epoch 351/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.4321 - mse: 17.4321 - val_loss: 18.9864 - val_mse: 18.9864\n",
      "Epoch 352/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.4623 - mse: 17.4623 - val_loss: 18.9102 - val_mse: 18.9102\n",
      "Epoch 353/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.4405 - mse: 17.4405 - val_loss: 19.2122 - val_mse: 19.2122\n",
      "Epoch 354/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.4075 - mse: 17.4075 - val_loss: 19.1290 - val_mse: 19.1290\n",
      "Epoch 355/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.3901 - mse: 17.3901 - val_loss: 18.9460 - val_mse: 18.9460\n",
      "Epoch 356/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.4568 - mse: 17.4568 - val_loss: 18.9070 - val_mse: 18.9070\n",
      "Epoch 357/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.4791 - mse: 17.4791 - val_loss: 19.3832 - val_mse: 19.3832\n",
      "Epoch 358/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.3813 - mse: 17.3813 - val_loss: 18.8616 - val_mse: 18.8616\n",
      "Epoch 359/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.4412 - mse: 17.4412 - val_loss: 19.8297 - val_mse: 19.8297\n",
      "Epoch 360/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.3982 - mse: 17.3982 - val_loss: 19.1119 - val_mse: 19.1119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.4067 - mse: 17.4067 - val_loss: 19.5870 - val_mse: 19.5870\n",
      "Epoch 362/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.3099 - mse: 17.3099 - val_loss: 18.5784 - val_mse: 18.5784\n",
      "Epoch 363/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.4091 - mse: 17.4091 - val_loss: 18.8623 - val_mse: 18.8623\n",
      "Epoch 364/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.3712 - mse: 17.3712 - val_loss: 19.1316 - val_mse: 19.1316\n",
      "Epoch 365/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.4039 - mse: 17.4039 - val_loss: 18.8459 - val_mse: 18.8459\n",
      "Epoch 366/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.4376 - mse: 17.4376 - val_loss: 18.4453 - val_mse: 18.4453\n",
      "Epoch 367/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.4403 - mse: 17.4403 - val_loss: 18.8134 - val_mse: 18.8134\n",
      "Epoch 368/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.4238 - mse: 17.4238 - val_loss: 19.1458 - val_mse: 19.1458\n",
      "Epoch 369/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.4070 - mse: 17.4070 - val_loss: 19.2206 - val_mse: 19.2206\n",
      "Epoch 370/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.3770 - mse: 17.3770 - val_loss: 18.9179 - val_mse: 18.9179\n",
      "Epoch 371/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.3727 - mse: 17.3727 - val_loss: 18.9297 - val_mse: 18.9297\n",
      "Epoch 372/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.3715 - mse: 17.3715 - val_loss: 19.2804 - val_mse: 19.2804\n",
      "Epoch 373/500\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 17.3869 - mse: 17.3869 - val_loss: 18.5935 - val_mse: 18.5935\n",
      "Epoch 374/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.3882 - mse: 17.3882 - val_loss: 18.8121 - val_mse: 18.8121\n",
      "Epoch 375/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.3665 - mse: 17.3665 - val_loss: 19.0942 - val_mse: 19.0942\n",
      "Epoch 376/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.4038 - mse: 17.4038 - val_loss: 19.2291 - val_mse: 19.2291\n",
      "Epoch 377/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.3742 - mse: 17.3742 - val_loss: 18.9072 - val_mse: 18.9072\n",
      "Epoch 378/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.4104 - mse: 17.4104 - val_loss: 19.1235 - val_mse: 19.1235\n",
      "Epoch 379/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.3157 - mse: 17.3157 - val_loss: 19.2148 - val_mse: 19.2148\n",
      "Epoch 380/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.3425 - mse: 17.3425 - val_loss: 19.1857 - val_mse: 19.1857\n",
      "Epoch 381/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.2961 - mse: 17.2961 - val_loss: 19.1694 - val_mse: 19.1694\n",
      "Epoch 382/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.3279 - mse: 17.3279 - val_loss: 19.1123 - val_mse: 19.1123\n",
      "Epoch 383/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.2895 - mse: 17.2895 - val_loss: 19.4953 - val_mse: 19.4953\n",
      "Epoch 384/500\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 17.3276 - mse: 17.3276 - val_loss: 19.3658 - val_mse: 19.3658\n",
      "Epoch 385/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.3278 - mse: 17.3278 - val_loss: 18.8129 - val_mse: 18.8129\n",
      "Epoch 386/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.3956 - mse: 17.3956 - val_loss: 18.9780 - val_mse: 18.9780\n",
      "Epoch 387/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.3670 - mse: 17.3670 - val_loss: 19.3007 - val_mse: 19.3007\n",
      "Epoch 388/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.2709 - mse: 17.2709 - val_loss: 18.8219 - val_mse: 18.8219\n",
      "Epoch 389/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.3400 - mse: 17.3400 - val_loss: 19.3391 - val_mse: 19.3391\n",
      "Epoch 390/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.3046 - mse: 17.3046 - val_loss: 19.4560 - val_mse: 19.4560\n",
      "Epoch 391/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.2151 - mse: 17.2151 - val_loss: 18.7956 - val_mse: 18.7956\n",
      "Epoch 392/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.3124 - mse: 17.3124 - val_loss: 18.9090 - val_mse: 18.9090\n",
      "Epoch 393/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.3112 - mse: 17.3112 - val_loss: 19.2320 - val_mse: 19.2320\n",
      "Epoch 394/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.2079 - mse: 17.2079 - val_loss: 18.7297 - val_mse: 18.7297\n",
      "Epoch 395/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.4276 - mse: 17.4276 - val_loss: 19.3195 - val_mse: 19.3195\n",
      "Epoch 396/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.2237 - mse: 17.2237 - val_loss: 18.5097 - val_mse: 18.5097\n",
      "Epoch 397/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.3614 - mse: 17.3614 - val_loss: 19.2112 - val_mse: 19.2112\n",
      "Epoch 398/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.2579 - mse: 17.2579 - val_loss: 19.2986 - val_mse: 19.2986\n",
      "Epoch 399/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.2978 - mse: 17.2978 - val_loss: 19.3774 - val_mse: 19.3774\n",
      "Epoch 400/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.2543 - mse: 17.2543 - val_loss: 19.1731 - val_mse: 19.1731\n",
      "Epoch 401/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.2659 - mse: 17.2659 - val_loss: 19.1239 - val_mse: 19.1239\n",
      "Epoch 402/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.2002 - mse: 17.2002 - val_loss: 18.8887 - val_mse: 18.8887\n",
      "Epoch 403/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.2437 - mse: 17.2437 - val_loss: 18.7613 - val_mse: 18.7613\n",
      "Epoch 404/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.2454 - mse: 17.2454 - val_loss: 18.4342 - val_mse: 18.4342\n",
      "Epoch 405/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.3795 - mse: 17.3795 - val_loss: 19.2599 - val_mse: 19.2599\n",
      "Epoch 406/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.2066 - mse: 17.2066 - val_loss: 18.8119 - val_mse: 18.8119\n",
      "Epoch 407/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.2558 - mse: 17.2558 - val_loss: 19.0768 - val_mse: 19.0768\n",
      "Epoch 408/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.2193 - mse: 17.2193 - val_loss: 19.2543 - val_mse: 19.2543\n",
      "Epoch 409/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.2090 - mse: 17.2090 - val_loss: 19.1630 - val_mse: 19.1630\n",
      "Epoch 410/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.2445 - mse: 17.2445 - val_loss: 18.5706 - val_mse: 18.5706\n",
      "Epoch 411/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.2962 - mse: 17.2962 - val_loss: 18.8033 - val_mse: 18.8033\n",
      "Epoch 412/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.1957 - mse: 17.1957 - val_loss: 18.4311 - val_mse: 18.4311\n",
      "Epoch 413/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.2770 - mse: 17.2770 - val_loss: 18.8283 - val_mse: 18.8283\n",
      "Epoch 414/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.2571 - mse: 17.2571 - val_loss: 19.1581 - val_mse: 19.1581\n",
      "Epoch 415/500\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 17.1944 - mse: 17.1944 - val_loss: 18.9900 - val_mse: 18.9900\n",
      "Epoch 416/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.2121 - mse: 17.2121 - val_loss: 19.1636 - val_mse: 19.1636\n",
      "Epoch 417/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.1740 - mse: 17.1740 - val_loss: 19.2184 - val_mse: 19.2184\n",
      "Epoch 418/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.1801 - mse: 17.1801 - val_loss: 18.8419 - val_mse: 18.8419\n",
      "Epoch 419/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.2205 - mse: 17.2205 - val_loss: 19.2644 - val_mse: 19.2644\n",
      "Epoch 420/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.1104 - mse: 17.1104 - val_loss: 18.8856 - val_mse: 18.8856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.2010 - mse: 17.2010 - val_loss: 19.3656 - val_mse: 19.3656\n",
      "Epoch 422/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.0711 - mse: 17.0711 - val_loss: 18.7083 - val_mse: 18.7083\n",
      "Epoch 423/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.2347 - mse: 17.2347 - val_loss: 19.1819 - val_mse: 19.1819\n",
      "Epoch 424/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.1401 - mse: 17.1401 - val_loss: 18.7537 - val_mse: 18.7537\n",
      "Epoch 425/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.2383 - mse: 17.2383 - val_loss: 19.2810 - val_mse: 19.2810\n",
      "Epoch 426/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.1660 - mse: 17.1660 - val_loss: 19.4870 - val_mse: 19.4870\n",
      "Epoch 427/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.1057 - mse: 17.1057 - val_loss: 18.6496 - val_mse: 18.6496\n",
      "Epoch 428/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.1763 - mse: 17.1763 - val_loss: 18.8287 - val_mse: 18.8287\n",
      "Epoch 429/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.0917 - mse: 17.0917 - val_loss: 18.3520 - val_mse: 18.3520\n",
      "Epoch 430/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.3174 - mse: 17.3174 - val_loss: 18.8757 - val_mse: 18.8757\n",
      "Epoch 431/500\n",
      "94/94 [==============================] - 1s 12ms/step - loss: 17.1117 - mse: 17.1117 - val_loss: 18.4454 - val_mse: 18.4454\n",
      "Epoch 432/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.1830 - mse: 17.1830 - val_loss: 18.8499 - val_mse: 18.8499\n",
      "Epoch 433/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.1541 - mse: 17.1541 - val_loss: 19.4943 - val_mse: 19.4943\n",
      "Epoch 434/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.0861 - mse: 17.0861 - val_loss: 18.8238 - val_mse: 18.8238\n",
      "Epoch 435/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.2251 - mse: 17.2251 - val_loss: 18.7180 - val_mse: 18.7180\n",
      "Epoch 436/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.1369 - mse: 17.1369 - val_loss: 18.8092 - val_mse: 18.8092\n",
      "Epoch 437/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.1228 - mse: 17.1228 - val_loss: 19.4244 - val_mse: 19.4244\n",
      "Epoch 438/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.0814 - mse: 17.0814 - val_loss: 19.4854 - val_mse: 19.4854\n",
      "Epoch 439/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.0808 - mse: 17.0808 - val_loss: 19.5024 - val_mse: 19.5024\n",
      "Epoch 440/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.0186 - mse: 17.0186 - val_loss: 18.9387 - val_mse: 18.9387\n",
      "Epoch 441/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.2104 - mse: 17.2104 - val_loss: 19.4654 - val_mse: 19.4654\n",
      "Epoch 442/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.0170 - mse: 17.0170 - val_loss: 18.6375 - val_mse: 18.6375\n",
      "Epoch 443/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.1870 - mse: 17.1870 - val_loss: 18.8775 - val_mse: 18.8775\n",
      "Epoch 444/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.1167 - mse: 17.1167 - val_loss: 19.3413 - val_mse: 19.3413\n",
      "Epoch 445/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.0381 - mse: 17.0381 - val_loss: 19.0760 - val_mse: 19.0760\n",
      "Epoch 446/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.0876 - mse: 17.0876 - val_loss: 19.5062 - val_mse: 19.5062\n",
      "Epoch 447/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.9913 - mse: 16.9913 - val_loss: 18.8447 - val_mse: 18.8447\n",
      "Epoch 448/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.0709 - mse: 17.0709 - val_loss: 18.9144 - val_mse: 18.9144\n",
      "Epoch 449/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.0303 - mse: 17.0303 - val_loss: 18.5651 - val_mse: 18.5651\n",
      "Epoch 450/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.2571 - mse: 17.2571 - val_loss: 18.7589 - val_mse: 18.7589\n",
      "Epoch 451/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.0087 - mse: 17.0087 - val_loss: 18.4368 - val_mse: 18.4368\n",
      "Epoch 452/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.1453 - mse: 17.1453 - val_loss: 18.8785 - val_mse: 18.8785\n",
      "Epoch 453/500\n",
      "94/94 [==============================] - 1s 8ms/step - loss: 17.0247 - mse: 17.0247 - val_loss: 18.6131 - val_mse: 18.6131\n",
      "Epoch 454/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.0945 - mse: 17.0945 - val_loss: 19.1951 - val_mse: 19.1951\n",
      "Epoch 455/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.9462 - mse: 16.9462 - val_loss: 18.6334 - val_mse: 18.6334\n",
      "Epoch 456/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.0143 - mse: 17.0143 - val_loss: 18.4842 - val_mse: 18.4842\n",
      "Epoch 457/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.0752 - mse: 17.0752 - val_loss: 19.1187 - val_mse: 19.1187\n",
      "Epoch 458/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.0190 - mse: 17.0190 - val_loss: 18.8176 - val_mse: 18.8176\n",
      "Epoch 459/500\n",
      "94/94 [==============================] - 1s 11ms/step - loss: 17.0355 - mse: 17.0355 - val_loss: 19.3325 - val_mse: 19.3325\n",
      "Epoch 460/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 16.9869 - mse: 16.9869 - val_loss: 19.2863 - val_mse: 19.2863\n",
      "Epoch 461/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.9365 - mse: 16.9365 - val_loss: 18.6819 - val_mse: 18.6819\n",
      "Epoch 462/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.9701 - mse: 16.9701 - val_loss: 18.8981 - val_mse: 18.8981\n",
      "Epoch 463/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.9962 - mse: 16.9962 - val_loss: 19.4621 - val_mse: 19.4621\n",
      "Epoch 464/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.9676 - mse: 16.9676 - val_loss: 18.5018 - val_mse: 18.5018\n",
      "Epoch 465/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.0688 - mse: 17.0688 - val_loss: 18.7590 - val_mse: 18.7590\n",
      "Epoch 466/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.9978 - mse: 16.9978 - val_loss: 18.4179 - val_mse: 18.4179\n",
      "Epoch 467/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.0502 - mse: 17.0502 - val_loss: 18.6792 - val_mse: 18.6792\n",
      "Epoch 468/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.0055 - mse: 17.0055 - val_loss: 19.5342 - val_mse: 19.5342\n",
      "Epoch 469/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.8770 - mse: 16.8770 - val_loss: 18.7618 - val_mse: 18.7618\n",
      "Epoch 470/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.9465 - mse: 16.9465 - val_loss: 18.6295 - val_mse: 18.6295\n",
      "Epoch 471/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.9641 - mse: 16.9641 - val_loss: 18.6710 - val_mse: 18.6710\n",
      "Epoch 472/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.9905 - mse: 16.9905 - val_loss: 19.0117 - val_mse: 19.0117\n",
      "Epoch 473/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.8894 - mse: 16.8894 - val_loss: 18.8444 - val_mse: 18.8444\n",
      "Epoch 474/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.9375 - mse: 16.9375 - val_loss: 19.4483 - val_mse: 19.4483\n",
      "Epoch 475/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.8927 - mse: 16.8927 - val_loss: 19.0859 - val_mse: 19.0859\n",
      "Epoch 476/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.8546 - mse: 16.8546 - val_loss: 18.6916 - val_mse: 18.6916\n",
      "Epoch 477/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 17.0088 - mse: 17.0088 - val_loss: 19.0796 - val_mse: 19.0796\n",
      "Epoch 478/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.8584 - mse: 16.8584 - val_loss: 19.1045 - val_mse: 19.1045\n",
      "Epoch 479/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.9323 - mse: 16.9323 - val_loss: 18.9449 - val_mse: 18.9449\n",
      "Epoch 480/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.9249 - mse: 16.9249 - val_loss: 19.3908 - val_mse: 19.3908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.8785 - mse: 16.8785 - val_loss: 19.0155 - val_mse: 19.0155\n",
      "Epoch 482/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.8628 - mse: 16.8628 - val_loss: 18.4644 - val_mse: 18.4644\n",
      "Epoch 483/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.9109 - mse: 16.9109 - val_loss: 18.6197 - val_mse: 18.6197\n",
      "Epoch 484/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.8662 - mse: 16.8662 - val_loss: 19.0627 - val_mse: 19.0627\n",
      "Epoch 485/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.9231 - mse: 16.9231 - val_loss: 18.8340 - val_mse: 18.8340\n",
      "Epoch 486/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.8495 - mse: 16.8495 - val_loss: 19.4825 - val_mse: 19.4825\n",
      "Epoch 487/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.8784 - mse: 16.8784 - val_loss: 18.9810 - val_mse: 18.9810\n",
      "Epoch 488/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.8314 - mse: 16.8314 - val_loss: 18.5031 - val_mse: 18.5031\n",
      "Epoch 489/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 17.0051 - mse: 17.0051 - val_loss: 19.5962 - val_mse: 19.5962\n",
      "Epoch 490/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.8361 - mse: 16.8361 - val_loss: 18.9477 - val_mse: 18.9477\n",
      "Epoch 491/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.9402 - mse: 16.9402 - val_loss: 19.1943 - val_mse: 19.1943\n",
      "Epoch 492/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.8322 - mse: 16.8322 - val_loss: 18.9648 - val_mse: 18.9648\n",
      "Epoch 493/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.8611 - mse: 16.8611 - val_loss: 19.1460 - val_mse: 19.1460\n",
      "Epoch 494/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.8410 - mse: 16.8410 - val_loss: 19.0266 - val_mse: 19.0266\n",
      "Epoch 495/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.8675 - mse: 16.8675 - val_loss: 18.7081 - val_mse: 18.7081\n",
      "Epoch 496/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 16.9022 - mse: 16.9022 - val_loss: 18.7256 - val_mse: 18.7256\n",
      "Epoch 497/500\n",
      "94/94 [==============================] - 1s 10ms/step - loss: 16.8520 - mse: 16.8520 - val_loss: 19.0400 - val_mse: 19.0400\n",
      "Epoch 498/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.8111 - mse: 16.8111 - val_loss: 18.6782 - val_mse: 18.6782\n",
      "Epoch 499/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.9118 - mse: 16.9118 - val_loss: 19.3374 - val_mse: 19.3374\n",
      "Epoch 500/500\n",
      "94/94 [==============================] - 1s 9ms/step - loss: 16.7870 - mse: 16.7870 - val_loss: 19.0745 - val_mse: 19.0745\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_dataset, validation_data=valid_dataset, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "S+P Week 3 Exercise Question.ipynb",
   "provenance": [
    {
     "file_id": "1E_dIdGjsU37D1klUJnB_OJdYwrSvTmxA",
     "timestamp": 1563504956880
    },
    {
     "file_id": "https://github.com/lmoroney/dlaicourse/blob/master/TensorFlow%20In%20Practice/Course%204%20-%20S%2BP/S%2BP%20Week%203%20Lesson%204%20-%20LSTM.ipynb",
     "timestamp": 1563486637817
    },
    {
     "file_id": "1M3Wn2-1epbDKQOcvYOepgi-pZSoOwwZN",
     "timestamp": 1561934268786
    },
    {
     "file_id": "1sGBr5jgLCXxWhNXC1ddMuxATeaYP8acr",
     "timestamp": 1561871087124
    },
    {
     "file_id": "1w4NClM1RKEfzmeK8uVGrTtxPt0NJmUhf",
     "timestamp": 1561778911582
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
